<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Clinical Brain Lab</title>
    <link>https://clinicalbrainlab.github.io/</link>
      <atom:link href="https://clinicalbrainlab.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>The Clinical Brain Lab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 22 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://clinicalbrainlab.github.io/images/icon_hu30d0ad82a56c1708370149d7b9443316_148842_512x512_fill_lanczos_center_3.png</url>
      <title>The Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/</link>
    </image>
    
    <item>
      <title>Introduction to the special issue: Bringing the brain into education: The application of findings from the Science of Learning to teacher training and development</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_science-of-learning_editorial/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_science-of-learning_editorial/</guid>
      <description>&lt;p&gt;The above is an editorial introducing a special issue of the journal &lt;b&gt;Trends in Neuroscience and Education&lt;/b&gt; &lt;i&gt;(Cite Score: 6.3; Impact Factor: 3.4)&lt;/i&gt; edited by &lt;b&gt;&lt;u&gt;Dr Adam John Privitera (CRADLE@NTU)&lt;/b&gt;&lt;/u&gt;, &lt;b&gt;&lt;u&gt;Professor S.H Annabel Chen (CRADLE@NTU)&lt;/b&gt;&lt;/u&gt;, &amp;amp; &lt;b&gt;&lt;u&gt;Associate Professor Maria Teresa Carthery-Goulart (Federal University of ABC, Brazil; The University of Hong Kong)&lt;/b&gt;&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;The special issue can be accessed through this link: 
&lt;a href=&#34;https://www.sciencedirect.com/special-issue/10054VJ6HG3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.sciencedirect.com/special-issue/10054VJ6HG3&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Music and Aging through the lens of Bayesian Inference</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_bayesian-inference-music-aging/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_bayesian-inference-music-aging/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Autonomic and respiratory changes in young and old adults with non-clinical depression and anxiety</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_autonomic-dep-anx/</link>
      <pubDate>Thu, 06 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_autonomic-dep-anx/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Does fiction reading influence Theory of Mind? An EEG study based on time-domain and time-frequency-domain approaches</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_fiction-reading-tom/</link>
      <pubDate>Thu, 06 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_fiction-reading-tom/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NLB EduConnect 2024</title>
      <link>https://clinicalbrainlab.github.io/talk/2024_nlb-brainnorm/</link>
      <pubDate>Wed, 29 May 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2024_nlb-brainnorm/</guid>
      <description>













  


&lt;video controls &gt;
  &lt;source src=&#34;featured.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
</description>
    </item>
    
    <item>
      <title>Cognitive and neural mechanisms of learning and interventions for improvement across the adult lifespan: A systematic review protocol</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_cog-neural-learning-review-protocol/</link>
      <pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_cog-neural-learning-review-protocol/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding of Psychological Literacy: Comparative Insights From Undergraduates in China and the United Kingdom</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_comparative-psychological-literacy/</link>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_comparative-psychological-literacy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AI and Aphasia in the Digital Age: A Critical Review</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_ai-aphasia-review/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_ai-aphasia-review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research Assistant Position at the Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_proof_ra/</link>
      <pubDate>Sun, 18 Feb 2024 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_proof_ra/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Clinical Brain Lab within the School of Social Sciences is seeking applications for the position of Research Assistant. The Research Assistant will be an integral member of an inter-disciplinary research lab developing and carrying out neuroimaging methodologies to investigate the neurocognitive processes underlying the belief of deceptive information.&lt;/p&gt;
&lt;p&gt;The successful candidate will be responsible for overseeing the day-to-day operations of research projects. This position requires task-orientation, excellent organizational skills, attention to details and accuracy, flexibility in responding to fluid situations, good interpersonal skills, as well as the ability to work independently. The main research modalities in our lab include neuropsychological assessments, cognitive tests, functional Magnetic Resonance (fMRI), diffusion MRI (DTI, HARDI, DSI), electroencephalography (EEG), Transcranial Magnetic Stimulation (TMS).&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Day to day coordination of funded projects.&lt;/li&gt;
&lt;li&gt;Preparation of ethics documents to institutional review boards.&lt;/li&gt;
&lt;li&gt;Participant recruitment.&lt;/li&gt;
&lt;li&gt;Data collection using neurophysiological recordings, such as electroencephalography.&lt;/li&gt;
&lt;li&gt;Liaise with stakeholders and project collaborators.&lt;/li&gt;
&lt;li&gt;Systems administration, including maintenance of network servers and data security.&lt;/li&gt;
&lt;li&gt;Contribute to the production of research reports.&lt;/li&gt;
&lt;li&gt;Perform other tasks as required by the Principal Investigators relevant to the research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bachelors (Honours) degree in Psychology, Cognitive Neuroscience or related field from University of good standing.&lt;/li&gt;
&lt;li&gt;Experience with electroencephalography is preferred.&lt;/li&gt;
&lt;li&gt;Good project coordination and administration skills, including data management and storage.&lt;/li&gt;
&lt;li&gt;Strong oral and written communication skills.&lt;/li&gt;
&lt;li&gt;Excellent organizational skills and able to work within given deadlines.&lt;/li&gt;
&lt;li&gt;Self-directed learner who effectively picks up relevant skills as needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;If you are interested in this job opening, please contact:&lt;/p&gt;
&lt;p&gt;Principal Investigator: Prof. Annabel Chen&lt;/p&gt;
&lt;p&gt;Email: 
&lt;a href=&#34;mailto:AnnabelChen@ntu.edu.sg&#34;&gt;AnnabelChen@ntu.edu.sg&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Subjective versus objective language proficiency measures in the investigation of bilingual effects on cognitive control</title>
      <link>https://clinicalbrainlab.github.io/publication/2024_bilingual-cognitive-control/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2024_bilingual-cognitive-control/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Is there a foreign language effect on academic integrity?</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_foreignlanguage-integrity/</link>
      <pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_foreignlanguage-integrity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading and Math in Young Children</title>
      <link>https://clinicalbrainlab.github.io/post/brainnorm/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/brainnorm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;brainnorm.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tracking gaze position from EEG: Exploring the possibility of an EEG-based virtual eye-tracker</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_eeg-eyetracker/</link>
      <pubDate>Mon, 18 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_eeg-eyetracker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Functional priority of syntax over semantics in Chinese ‘ba’ construction: evidence from eye-tracking during natural reading</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_chinese-syntax-semantics/</link>
      <pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_chinese-syntax-semantics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Perception of Real vs. Fake Information</title>
      <link>https://clinicalbrainlab.github.io/project/fake-news/</link>
      <pubDate>Thu, 24 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/fake-news/</guid>
      <description>&lt;p&gt;Deception, or in other words, information that does not reflect reality, created or delivered with the intention of duping the receiver, is increasingly prevalent in the age of social media. With virtual reality, augmented reality, uncontrolled mass communication, and new forms of fiction, it becomes increasingly difficult to separate truth from deception. Moreover, brain mechanisms and other physiological correlates underlying the processing and acceptance of deceptive information remain largely unknown. This study will be a critical first step in understanding how deceitful information becomes endorsed by individuals susceptible to fake news beliefs and conspiracy theories, consequently facilitating counteract measures in the future.&lt;/p&gt;
&lt;p&gt;The first aim of this study is to establish and validate a strong experimental paradigm for investigating the neurocognitive processes underlying the belief in deceptive (i.e., Fake/Real) information. It should be noted that real and fake in this study is defined by the factual accuracy of the information based on current credible news. The second aim is to investigate how these processes can be experimentally modulated and the extent of their impact on one&amp;rsquo;s deception appraisal. This paradigm will then help to build a computational model of reality belief which in turn will be used to predict the effect of specific interventions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creative Writing</title>
      <link>https://clinicalbrainlab.github.io/post/proof/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/proof/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./proof.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Cognition through Dance in Older Filipinos with MCI</title>
      <link>https://clinicalbrainlab.github.io/project/indak/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/indak/</guid>
      <description>&lt;p&gt;The project aims to provide scientific evidence on a public health intervention that is contextualized in a community setting to reduce dementia risk among older adults with MCI. This is a cluster-randomized, two-arm, single-blind trial of a multicomponent intervention that combines dance called INDAK (Improving Neurocognition through Dance and Kinesthetics), nutrition counseling, and vascular risk management. The intervention group received 12-16 months of dance sessions and vascular management while the control group (CON) received only the vascular management.
The primary outcome is cognitive performance assessed by several behavioral tasks. Secondary outcomes are functional connectivity assessed through brain imaging, and measures of behavioral, functional level, and quality of life. This model can be an ecological, low-cost, and effective program, thereby conducive to widespread implementation in the Philippines as well as in other low-resource settings with similar public health challenges.
This project is a collaboration with St. Luke&amp;rsquo;s Medical Center, Institute for Neurosciences, Quezon City, Philippines.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Ongoing Project:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/34557142/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FINOMAIN: FIlipiNO Dance Intervention to MAINtain Cognitive Performance in High Risk Population&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>BrainConnects 2023</title>
      <link>https://clinicalbrainlab.github.io/talk/2023_brainconnects/</link>
      <pubDate>Sat, 19 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2023_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://www.brainconnects2023.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2023.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cerebellum &amp; Language</title>
      <link>https://clinicalbrainlab.github.io/project/cerebellum-language/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/cerebellum-language/</guid>
      <description>&lt;p&gt;Cerebellum has increasingly been recognized for its contributions beyond motor control to higher cognitive functions. Our work focuses on the roles of cerebellum in language. We use neuroimaging techniques to examine the cerebellar involvement and the cerebro-cerebellar contributions towards language and reading-related processes.&lt;/p&gt;
&lt;p&gt;The findings highlight the role of the cerebellum in reading networks. The implications underscore the need for further research on heterogeneity of cerebellar functions and cerebro-cerebellar functional connectivity to develop a comprehensive understanding of the neural correlates of reading.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Research Output:&lt;/u&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Conference:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2023_ohbm_cerebellum-reading/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mapping the Cerebellum to the Neural Network of Reading in Bilinguals&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Brain Networks of Reading and Math</title>
      <link>https://clinicalbrainlab.github.io/project/brain-norm/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/brain-norm/</guid>
      <description>&lt;p&gt;Tapping on the advancements of neuroimaging, the project aims to develop a combination of behavioural measures that may be as sensitive as neuroimaging measures to delineate the different learning disabilities subgroups in young children. There is a growing prevalence of learning disabilities (LD) in Reading Difficulties (RD), Math Difficulties (MD) and their comorbidity (Reading-Math Difficulties; RMD) in young children. Given the important roles math and reading play in the development of emerging skills during early school years, early identification is crucial.&lt;/p&gt;
&lt;p&gt;Using advanced neuroimaging methods, we aim to better understand the extent to which reading, math and working memory are subserved by common neural substrates at the individual level. We will then further examine these networks in combination with learning disabilities screeners, which will help to distinguish children with RD, MD and RMD at the neural level. We aim to then identify existing sensitive screening tools to delineate the LD subgroups, which will allow prediction to intervention responsiveness, and enable better tailoring of the intervention these young children will receive from the onset.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Ongoing Projects:&lt;/u&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project 1:&lt;/b&gt; Cognitive Screen and Characterization of Reading and Math Skills&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project 2:&lt;/b&gt; Differentiating the Brain Networks underpinning Reading and Math (Structural MRI, Diffusion MRI, Resting-state Functional MRI, Task-based Functional MRI)&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project 3:&lt;/b&gt; Examining the functional brain networks supporting reading using fNIRS&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project 4:&lt;/b&gt; Examining the functional brain networks supporting math using fNIRS&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project 5:&lt;/b&gt; Learning Support in Action&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Defining the Science of Learning: A Scoping Review</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_science-of-learning_review/</link>
      <pubDate>Sun, 13 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_science-of-learning_review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MRI Space Mission</title>
      <link>https://clinicalbrainlab.github.io/post/kid-biliteracy/</link>
      <pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/kid-biliteracy/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;main.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Age-Related Changes in Episodic Processing of Scenes: A Functional Activation and Connectivity Study</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_aging_sensors/</link>
      <pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_aging_sensors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our Bilingual Future</title>
      <link>https://clinicalbrainlab.github.io/talk/2023_bilingual_future/</link>
      <pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2023_bilingual_future/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Associations between brain structure, HRV, and depression and anxiety in a non-clinical sample</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_hrv-affective/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_hrv-affective/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HRV mediates the relationship between isthmus cingulate thickness and inhibitory control</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_hrv-cognition/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_hrv-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mapping the Cerebellum to the Neural Network of Reading in Bilinguals</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_ohbm_cerebellum-reading/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_ohbm_cerebellum-reading/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Social Dance to Maintain Cognitive Performance and Cortical Morphology in Older Adults with MCI</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_ohbm_dancing/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_ohbm_dancing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Theta-burst stimulation-induced cortical plasticity in younger and older adults: a TMS-EEG study</title>
      <link>https://clinicalbrainlab.github.io/publication/2023_tmseeg-youngold/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2023_tmseeg-youngold/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain entropy, fractal dimensions and predictability: A review of complexity measures for EEG in healthy and neuropsychiatric populations</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_brain-entropy/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_brain-entropy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2022</title>
      <link>https://clinicalbrainlab.github.io/talk/2022_brainconnects/</link>
      <pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2022_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/view/brainconnects2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2022.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Structure of Chaos: An Empirical Comparison of Fractal Physiology Complexity Indices Using NeuroKit2</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_structure-of-chaos/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_structure-of-chaos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do labels matter? The effect of specific and generic labels on university students’ openness towards autistic peers</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_labels/</link>
      <pubDate>Sat, 23 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_labels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Theta Power Differences as a Function of Level of Familiarity with a Musical Style</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_music-familiarity/</link>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_music-familiarity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Closer Look at Cardiac Contraction and the Effect of Cardiac Timing on Cognitive Control</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_cocon/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_cocon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fractal Dimensions of EEG Activity is Linked to Distinct Facets of Resting-State Cognition</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_restingstatecomplexity/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_restingstatecomplexity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the effects of background noise and music on cognitive test performance in introverts and extraverts: A cross-cultural study</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_background-music/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_background-music/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cerebellar Transcranial Magnetic Stimulation (TMS) Impairs Visual Working Memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2022_cerebellar-tms/</link>
      <pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2022_cerebellar-tms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Part-time Student Assistant Position at CRADLE</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_part-time-ra/</link>
      <pubDate>Fri, 11 Feb 2022 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_part-time-ra/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Centre for Research and Development in Learning (CRADLE), led by Principal Investigator Prof. Annabel Chen, is looking to hire several part-time undergraduate research assistants.&lt;/p&gt;
&lt;p&gt;You will be part of a dynamic team of researchers who apply multi-modal approaches, including neurocognitive assessments, and neuroimaging techniques such as magnetic resonance imaging (MRI) and functional near-infrared spectroscopy (fNIRS) to investigate the neurocognitive mechanisms of literacy and numeracy development in young children.&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;Depending on the study you are assisting in, you might be involved in some of the following activities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assist with participant recruitment and eligibility screening&lt;/li&gt;
&lt;li&gt;Assist with behavioural, fNIRS and/or MRI data collection&lt;/li&gt;
&lt;li&gt;Assist with data coding, maintenance and preprocessing&lt;/li&gt;
&lt;li&gt;Assist with the translation of research documents&lt;/li&gt;
&lt;li&gt;Other activities that support the research studies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You must be a current undergraduate student at Nanyang Technological University (NTU)&lt;/li&gt;
&lt;li&gt;A self-directed learner who is eager to learn about advanced neuroimaging research&lt;/li&gt;
&lt;li&gt;Prior experience or have interests in working with young children&lt;/li&gt;
&lt;li&gt;Ability to work on some weekends (for data collection)&lt;/li&gt;
&lt;li&gt;Previous experience in neurocognitive or neuroimaging research is an advantage&lt;/li&gt;
&lt;li&gt;Ability to help with translations (i.e. Mandarin, Malay or Tamil) is an advantage&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;If you are interested in this job opening, please contact:&lt;/p&gt;
&lt;p&gt;Research Fellow: Dr. Lynette Looi&lt;/p&gt;
&lt;p&gt;Email: 
&lt;a href=&#34;mailto:lynette.looi@ntu.edu.sg&#34;&gt;lynette.looi@ntu.edu.sg&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;flyer&#34;&gt;Flyer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/join/BrainNORM.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calling for Submissions to Special Issue &#34;Brain Activity Monitoring and Measurement&#34;</title>
      <link>https://clinicalbrainlab.github.io/talk/2021_submission_sensors/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2021_submission_sensors/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://www.mdpi.com/journal/sensors/special_issues/BAMM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link for more information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sex difference in tDCS current mediated by changes in cortical anatomy: A study across young, middle and older adults</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_sex-differences-tdcs/</link>
      <pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_sex-differences-tdcs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2021</title>
      <link>https://clinicalbrainlab.github.io/talk/2021_brainconnects/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2021_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;http://thebrainx.com/brainconnects2021/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2021.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Focality-Oriented Selection of Current Dose for Transcranial Direct Current Stimulation</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_tdcs-dtdi/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_tdcs-dtdi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain Entropy, Fractal Dimensions and Predictability: A Review of Complexity Measures for EEG in Healthy and Neuropsychiatric Populations</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_braincomplexity/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_braincomplexity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Parametric Framework to Generate Visual Illusions using Python</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_pyllusion/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_pyllusion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heart Rate Variability in Psychology: A Review of HRV Indices and an Analysis Tutorial</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_hrv/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_hrv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Structure of Deception: Validation of the Lying Profile Questionnaire</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_deception-scale/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_deception-scale/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NeuroKit2: A Python toolbox for neurophysiological signal processing</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_neurokit/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_neurokit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Individual-fMRI-approaches reveal cerebellum and visual communities to be functionally connected in obsessive compulsive disorder</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_cerebellum-ocd/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_cerebellum-ocd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aging patterns of Japanese auditory semantic processing: an fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_ageing-adutiroy-processing/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_ageing-adutiroy-processing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading proficiency influences the effects of transcranial direct current stimulation: Evidence from selective modulation of dorsal and ventral pathways of reading in bilinguals</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_learning-biliteracy-tdcs/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_learning-biliteracy-tdcs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Psychological Determinants of the Susceptibility to Fake News amidst the COVID-19 Pandemic</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_deception-covid-fakenews/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_deception-covid-fakenews/</guid>
      <description>&lt;p&gt;As the COVID-19 outbreak spreads across the globe, the world is in parallel flooded by information reporting a wide range of facts, which veracity is not always verifiable.
Indeed, it has become increasingly apparent that the COVID-19 fake news pandemic is becoming just as viral as the outbreak of the disease itself, evidenced by the need for researchers
and authorities to track the spread of misinformation. As a consequence, the Ministry of Health in Singapore has even dedicated an entire website (See here: 
&lt;a href=&#34;https://www.moh.gov.sg/covid-19/clarifications&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.moh.gov.sg/covid-19/clarifications&lt;/a&gt;) to debunk all instances of fake news.&lt;/p&gt;
&lt;h2 id=&#34;the-role-of-conspiracy-theories&#34;&gt;The Role of Conspiracy Theories&lt;/h2&gt;
&lt;p&gt;While the authorities are struggling to provide concrete explanations about the coronavirus, conspiracy theorists are quick to provide competing ones with confidence.
This has exaggerated the spread of fake news and conspiracy theories - beliefs that seek to explain the cause of an event by a hidden, wicked and unlawful scheme, without scientific support.
For instance, a theory that the new 5G technology causes the spread of coronavirus outbreak was widely circulated and peddled by conspiracy theorists.
Studies have shown that conspiracy theories are often endorsed by people who feel powerless. Their rejection of mainstream accounts and adoption of conspiracy explanations is an attempt to make sense of the world beyond their control (Swami &amp;amp; Furnham, 2010).
The uncertainties brought about by the COVID-19 pandemic might prompt people, especially individuals with higher schizotypal tendencies (characterized by suspicion, social anxiety and paranoid ideation), to engage in this sense-making mechanism, seeking alternative explanations
to regain their sense of control. People who have the tendency to adopt conspiracy theories have been found to rely more on intuition (Pennycook, Cheyne, Barr, Koehler &amp;amp; Fugelsang, 2015; Pennycook &amp;amp; Rand, 2018) and are hence more susceptible to fake news beliefs.&lt;/p&gt;
&lt;h2 id=&#34;the-role-of-emotions&#34;&gt;The Role of Emotions&lt;/h2&gt;
&lt;p&gt;In a global pandemic where the world is in a constant elevated state of anxiety, fake news beliefs can befall anyone for reasons beyond just the persistent cognitive biases that characterize conspiracist theorists.
People are often left feeling fearful and anxious due to the endless bombardment of pandemic news information, regardless of its accuracy.
Fake news on COVID-19 are especially emotionally engaging because they play on people’s helplessness by offering some miracle remedy or fueling anger towards authorities handling the situation.&lt;/p&gt;
&lt;p&gt;A research team led by Gordon Pennycook, a researcher on the psychology of misinformation, found that individuals are more likely to perceive fake news headlines as accurate when they were in an emotional state (Martel et al., 2019). At the Clinical Brain Lab, we have started research into this area during the
Circuit Breaker period. We propose that the underlying factor driving susceptibility to fake news beliefs is not just the mere presence of negative affect, but how one regulates these emotions.
This refers to the ability to control one’s emotional state, such as considering alternative interpretations of an otherwise negative situation.&lt;/p&gt;
&lt;p&gt;In the context of the COVID-19 pandemic, an important aspect of emotion regulation is being able to navigate through the uncertainties of the future. With future plans now at a standstill and emotions running high, we become less tolerant of uncertainty and feel more helpless about our circumstances.
Poor self-control makes us cognitively lazy, believing something because “it feels right” and aligned with our emotions. Fast, intuitive processing thus often takes precedence over effortful and reflective thinking, of which the latter is needed to discern whether a piece of news is real or fake (Pennycook &amp;amp; Rand, 2019).
We are thus more vulnerable to engaging in fake news than we think.&lt;/p&gt;
&lt;h2 id=&#34;our-research&#34;&gt;Our Research&lt;/h2&gt;
&lt;p&gt;As it is important to delineate the psychological determinants of the belief in fake news as part of a global effort in combating misinformation, Prof Annabel Chen together with Research Fellow Dr Dominique Makowski and research assistants (Pham Thanh Tam and Lau Zen Juen) are currently conducting an investigation into the spread of COVID-19 fake news in Singapore.
Specifically, this study seeks to examine whether the belief in conspiracy theories and one’s ability to regulate emotions are related to one’s tendency to fall prey to fake news.
This study is pre-registered at 
&lt;a href=&#34;https://osf.io/7d3xh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSF&lt;/a&gt; and currently undergoing data analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Centre for Lifelong Learning and Individualised Cognition</title>
      <link>https://clinicalbrainlab.github.io/project/clic/</link>
      <pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/clic/</guid>
      <description>&lt;p&gt;Our projects seek to make cognitive neuroscience findings accessible to educators and facilitate collaborative work between educators and researchers.
As technology and globalisation are changing the nature of labour markets and increasing the demand for high levels of skill, the need for individuals to be able to develop new skills during their working careers is becoming increasingly pressing. While there is an increased recognition of the need for flexible behavioural and transferable skills, there is currently a gap in evidence-based training programmes that can effectively support and promote cognitive flexibility across the life course.&lt;/p&gt;
&lt;p&gt;The Centre for Lifelong Learning and Individualised Cognition (CLIC) programme aims to address this gap by developing innovative research in the science of learning and translating it to educational and real-life applications across the life course. We will adopt an integrated interdisciplinary approach that marries cross-disciplinary expertise and methodologies across Cambridge and NTU to target three life periods (early years, adolescence, middle age) when flexible behaviour is critical for coping with highly changing circumstances. Working together, we aspire to provide Singapore with a competitive leading edge in the Science of Learning through its transformative theory, methodological innovation, and high-impact practical outcomes.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Ongoing Project:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding and promoting individual cognitive flexibility – funded by National Research Foundation, Prime Minister’s Office Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) programme.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on the CLIC programme, please visit the official webpage at this link: 
&lt;a href=&#34;https://www.cares.cam.ac.uk/research/clic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CLIC&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Active Aging Lifestyle</title>
      <link>https://clinicalbrainlab.github.io/project/ageing/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/ageing/</guid>
      <description>&lt;p&gt;Combining both cognitive and exercise training in an intervention program may be advantageous to enhance cognitive and physical functions.
However, this approach has yet to be well researched and implemented. Given the hot and humid climate and community environments (e.g., sidewalks and street traffic) in Singapore, common aerobic exercises such as walking and jogging may not be the first choice for sedentary older adults in Singapore.
Therefore, we proposed and developed an intervention program (&lt;strong&gt;ExCITE: Exercise-Cognition Integrated Training for Enhancement&lt;/strong&gt;) that incorporates both cognitive and physical exercise components that can be easily implemented and weaved into the lifestyles of our aging population.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Research Output:&lt;/u&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://doi.org/10.1186/s13102-021-00309-w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Acute effects of Square Stepping Exercise on cognitive and social functions in sedentary young adults: A home-based online trial.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://doi.org/10.15294/ajpesh.v2i2.62184&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Short-term effects of Square Stepping Exercise on cognitive and social functions in sedentary older adults: A home-based online trial.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; 
&lt;a href=&#34;http://www.clinicalbrain.org/publication/2023_tmseeg-youngold/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theta-burst stimulation-induced cortical plasticity in younger and older adults: a TMS-EEG study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; 
&lt;a href=&#34;http://www.clinicalbrain.org/publication/2023_hrv-affective/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Associations between brain structure, HRV, and depression and anxiety in a non-clinical sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; 
&lt;a href=&#34;http://www.clinicalbrain.org/publication/2023_hrv-cognition/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HRV mediates the relationship between isthmus cingulate thickness and inhibitory control&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Alumni of Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/alumni/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/alumni/</guid>
      <description>&lt;p&gt;Nanyang Technological University (Singapore):
&lt;/br&gt;&lt;/br&gt;
Undergraduate Students&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amos Law&lt;/li&gt;
&lt;li&gt;Arumugam Ramaswamy&lt;/li&gt;
&lt;li&gt;Cheng Wenxuan&lt;/li&gt;
&lt;li&gt;Chia Kai Xin&lt;/li&gt;
&lt;li&gt;Chui Yingqi&lt;/li&gt;
&lt;li&gt;Dawn Lim&lt;/li&gt;
&lt;li&gt;Derric Eng&lt;/li&gt;
&lt;li&gt;Ebenezer Chan&lt;/li&gt;
&lt;li&gt;Esmond Seow&lt;/li&gt;
&lt;li&gt;Goh Jing Tian&lt;/li&gt;
&lt;li&gt;Goh Siang Loo, Serene&lt;/li&gt;
&lt;li&gt;Helen Ho&lt;/li&gt;
&lt;li&gt;Jarrad Oh&lt;/li&gt;
&lt;li&gt;Jasmine Lim&lt;/li&gt;
&lt;li&gt;Jermaine Chu&lt;/li&gt;
&lt;li&gt;Khoo Ser Wee&lt;/li&gt;
&lt;li&gt;Lean Jing Hui&lt;/li&gt;
&lt;li&gt;Leong Li An&lt;/li&gt;
&lt;li&gt;Lim Tech Yian&lt;/li&gt;
&lt;li&gt;Lin Xiaowen&lt;/li&gt;
&lt;li&gt;Low Jia Rong&lt;/li&gt;
&lt;li&gt;Mabel Ong&lt;/li&gt;
&lt;li&gt;Matthew Teo&lt;/li&gt;
&lt;li&gt;Megan Tay&lt;/li&gt;
&lt;li&gt;Michelle Mah&lt;/li&gt;
&lt;li&gt;Neo Shao Hoon&lt;/li&gt;
&lt;li&gt;Neo Yi Fang&lt;/li&gt;
&lt;li&gt;Nur Diyanah&lt;/li&gt;
&lt;li&gt;Ong Zi Yan&lt;/li&gt;
&lt;li&gt;Rachel Tham&lt;/li&gt;
&lt;li&gt;Randal Lee Zhisheng&lt;/li&gt;
&lt;li&gt;Regine Lau&lt;/li&gt;
&lt;li&gt;Samuel Chong&lt;/li&gt;
&lt;li&gt;Seanna Neo&lt;/li&gt;
&lt;li&gt;Serene Koh&lt;/li&gt;
&lt;li&gt;Sharon Chan&lt;/li&gt;
&lt;li&gt;Shee Mei Ling&lt;/li&gt;
&lt;li&gt;Stephanie Lee&lt;/li&gt;
&lt;li&gt;Tan Suan Fong&lt;/li&gt;
&lt;li&gt;Tay Shi Ying&lt;/li&gt;
&lt;li&gt;Teh Hui Chian&lt;/li&gt;
&lt;li&gt;Tony Lim&lt;/li&gt;
&lt;li&gt;Vicki Chng Wei Qi&lt;/li&gt;
&lt;li&gt;Yap Jia Yu&lt;/li&gt;
&lt;li&gt;Yeo Jia Ying&lt;/li&gt;
&lt;li&gt;Yeo Siok Peng&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graduate Students&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chan Yee Pei&lt;/li&gt;
&lt;li&gt;Eng Goi Khia&lt;/li&gt;
&lt;li&gt;Gladys Heng&lt;/li&gt;
&lt;li&gt;Kwok Fu Yu&lt;/li&gt;
&lt;li&gt;Tan Jiat Chow&lt;/li&gt;
&lt;li&gt;Wu Chiao-Yi (Joyce)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Research Fellows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adrian Galang, PhD&lt;/li&gt;
&lt;li&gt;Belle Yick, PhD&lt;/li&gt;
&lt;li&gt;Dominique Makowski, PhD&lt;/li&gt;
&lt;li&gt;Jo Archer, PhD&lt;/li&gt;
&lt;li&gt;Lee Shu Hui, PhD&lt;/li&gt;
&lt;li&gt;Liu Heng Shuang, PhD&lt;/li&gt;
&lt;li&gt;Monika Sobczak-Edmans, PhD&lt;/li&gt;
&lt;li&gt;Nestor Vinas-Guasch, PhD&lt;/li&gt;
&lt;li&gt;Rajan Kashyap, PhD&lt;/li&gt;
&lt;li&gt;Tommy Ng, PhD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Research Associates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alvin Lim, MA&lt;/li&gt;
&lt;li&gt;Cathy Kao, MS&lt;/li&gt;
&lt;li&gt;Hoki Fung, MS&lt;/li&gt;
&lt;li&gt;Ilang Kumaran Yuvadarshini, MS&lt;/li&gt;
&lt;li&gt;Meenakshi Siddharthan, MS&lt;/li&gt;
&lt;li&gt;Stephanie Kirk, MA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Project Officers/Research Assistants&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adhya Neshaa Nedumaran&lt;/li&gt;
&lt;li&gt;Alison Chew&lt;/li&gt;
&lt;li&gt;Cheng Wenxuan&lt;/li&gt;
&lt;li&gt;Gan Su Ren&lt;/li&gt;
&lt;li&gt;Lau Zen Juen&lt;/li&gt;
&lt;li&gt;Low Li Tong&lt;/li&gt;
&lt;li&gt;Marilyn Yeo&lt;/li&gt;
&lt;li&gt;Ngoi Zi Liang&lt;/li&gt;
&lt;li&gt;Phoebe Chia&lt;/li&gt;
&lt;li&gt;Tam Pham&lt;/li&gt;
&lt;li&gt;Tan Bee Li&lt;/li&gt;
&lt;li&gt;Te An Shu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interns&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elaine Teo, Intern&lt;/li&gt;
&lt;li&gt;Jonathan Tan&lt;/li&gt;
&lt;li&gt;Max Yong, Trainee RA&lt;/li&gt;
&lt;li&gt;Pavitraa Sundram, Trainee RA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;System Admin&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lua Rui Ping, PhD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/br&gt;&lt;/br&gt;
National Taiwan University (Taiwan):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Andy Chen, MS&lt;/li&gt;
&lt;li&gt;Camilla Chen, MS&lt;/li&gt;
&lt;li&gt;Cecilia Peng, MS&lt;/li&gt;
&lt;li&gt;Ching-I Lu, MS&lt;/li&gt;
&lt;li&gt;Eva Lin, MS&lt;/li&gt;
&lt;li&gt;Evan Song&lt;/li&gt;
&lt;li&gt;Ivy Cheng, MS&lt;/li&gt;
&lt;li&gt;Jessie Huang, MS&lt;/li&gt;
&lt;li&gt;Jing-Syun (Edward) Yu&lt;/li&gt;
&lt;li&gt;Kayako Matsuo, PhD&lt;/li&gt;
&lt;li&gt;Linda Sung, MS&lt;/li&gt;
&lt;li&gt;Max Chen&lt;/li&gt;
&lt;li&gt;Naichi Ko, MS&lt;/li&gt;
&lt;li&gt;Pao-Hsiung Chiu&lt;/li&gt;
&lt;li&gt;Psyche Hou, MS&lt;/li&gt;
&lt;li&gt;Shu-Ju Yang&lt;/li&gt;
&lt;li&gt;Siny Tsang&lt;/li&gt;
&lt;li&gt;Yu-Ru Chiu, MS&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Behavioural and Neural Correlates of Deception</title>
      <link>https://clinicalbrainlab.github.io/project/deception/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/deception/</guid>
      <description>&lt;p&gt;Traditional lie detection as used in polygraph test is based on examining one&amp;rsquo;s physiological arousal (measuring skin conductance,
heart rate, and respiration) to infer lying. However, such physiological arousal may merely be reflecting anxiety and fear during a polygraph examination,
rather than lying per se.&lt;/p&gt;
&lt;p&gt;As physiological arousal could not be used to accurately infer lying, researchers are urged to further look into the mental processes related to lying.
To date, different neurophysiological signals, including functional magnetic resonance imaging (fMRI) and event-related potentials (ERP) have been studied for possible application to index deception.
Past studies have shown evidences that strongly supporting the hypothesis that deception requires the coordination of multiple cognitive processes and thus is more cognitively taxing than truth telling.
Despite the positive findings, previous studies were often criticized for not capturing lying as it exists in the real world. Indeed, majority of the experimental paradigms required participants to lie about perceptual
stimuli or memorized materials. More importantly, unlike lying in the real world, the lies generated in research labs were often not spontaneous but instructed.&lt;/p&gt;
&lt;p&gt;To increase the translational value of the research in deception and lie detection, we aim to investigate the neural correlates of lying using paradigms that can elicit lying similar to those in the real world.
In addition, we also seek to explore the structure of dispositional deception by developing and validating a short and reliable questionnaire to characterize individuals&amp;rsquo; lying patterns.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bilingual Reading Networks</title>
      <link>https://clinicalbrainlab.github.io/project/reading-network/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/reading-network/</guid>
      <description>&lt;p&gt;Our projects aim to elucidate the neurocognitive mechanisms underlying typical and impaired reading in bilinguals.
We use a combination of behavioural assessment and neuroimaging techniques to investigate the neural reading networks for bilingual readers from a variety of language profiles, across early childhood and adulthood.
Our projects will shed light on the impact of critical factors (e.g., orthographic depth of scripts, auditory perception skills) on the bilingual reading networks. Our findings will provide implications for neuroscience-informed remediation of reading difficulties for bilingual readers.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Completed Projects:&lt;/u&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Effective Biliteracy: The Impact of Script Sets on Bilingual Reading Networks for Typical and Atypical Readers - &lt;em&gt;funded by NTU-JHU Collaborative Grant&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Modulating Reading Networks -&lt;em&gt;funded by NTU-JHU Collaborative Grant&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Cognitive Science of Multilingualism In Children (COSMIC) - &lt;em&gt;funded by National Research Foundation&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;u&gt;Research Output:&lt;/u&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2020_learning-biliteracy-tdcs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reading proficiency influences the effects of transcranial direct current simulation: Evidence from selective modulation of dorsal and ventral pathways of reading in bilinguals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2020_tdcs-montages-simulation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simulation analyses of tDCS montages for the investigation of dorsal and ventral pathways&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; Scripts of Mother Tongues Affect Cortical Structure in Bilinguals&amp;rsquo; Reading Network&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; The Impact of Script Sets on the Functional Organization of Bilinguals&amp;rsquo; Reading Network&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; Cortical structures in the reading network correlate with reading proficiency in early bilinguals&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Conference Poster:&lt;/b&gt; Could tDCS Modulate Bilingual Reading?&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Promoting Effective Biliteracy</title>
      <link>https://clinicalbrainlab.github.io/project/pebbles/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/pebbles/</guid>
      <description>&lt;p&gt;The project aims to develop an early screening and training programme to promote balanced bilingual development and biliteracy attainment in early childhood.
Using a multimodal approach, we will identify early neural, cognitive, and environmental predictors in preschool years for later bilingual and biliteracy development.
We will evaluate the neurocognitive effects of different training programmes on enhancing biliteracy development. The knowledge gained from the project will broaden our understanding of the neurocognitive development of language and reading networks in young bilinguals.
The findings will have significant implications for early screening and effective training for promoting balanced bilingual and biliteracy development.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Ongoing Project:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Promoting Effective Biliteracy in Early Childhood: A Systematic Screening and Training Programme for Balanced Bilingual Development - &lt;em&gt;funded by Singapore Millennium Foundation&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Translating neuroscience for educators</title>
      <link>https://clinicalbrainlab.github.io/project/translate-neuro/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/translate-neuro/</guid>
      <description>&lt;p&gt;Our projects seek to make cognitive neuroscience findings accessible to educators and facilitate collaborative work between educators and researchers.
The broad goals of our research are to encourage and strengthen dialogue between researchers, practitioners and the wider community to consolidate existing knowledge and generate new hypotheses to answer real-world questions in education and learning.
To achieve these goals we utilise a range of approaches, including language translations, open database platforms, meta-analyses and meta-analytic brain connectivity modelling, data-visualisation and focus group discussions.
This work has important implications in developing educator’s brain literacy and informing teaching and learning to support the growing population of diverse child and adult learners.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Ongoing Project:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding functional relationships between socio-affective and neurocognitive brain networks in adults with ASD and ADHD to better inform learning for learners and educators: Towards maximising the adult learning potential&lt;/li&gt;
&lt;li&gt;Developing educator’s Brain Literacy: BrainMap for Teacher Professional Development (DEV 01/21 AMG) (Funded by MOE-ERFP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;u&gt;Completed Project:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.nie.edu.sg/research/projects/project/afd-07-16-zw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Developing a translating educational neuroscience clearinghouse (TENC) for the differentiated instruction of diverse learners&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>i-SATA: A MATLAB based toolbox to estimate current density generated by transcranial direct current stimulation in an individual brain</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_isata/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_isata/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The role of primary motor cortex: More than movement execution</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_m1-review/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_m1-review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Indices of effect existence and significance in the Bayesian framework</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_bayesian/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_bayesian/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Maximizing dissimilarity in resting state detects heterogeneous subtypes in healthy population associated with high substance use and problems in antisocial personality</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_rsfmri-subtypes/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_rsfmri-subtypes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2019</title>
      <link>https://clinicalbrainlab.github.io/talk/2019_brainconnects/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2019_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2019/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Translating education neuroscience for teachers</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_learning-translating/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_learning-translating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain literacy empowers educators to meet diverse learner needs</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_learning-brain-literacy/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_learning-brain-literacy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulation analyses of tDcS montages for the investigation of dorsal and ventral pathways</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_tdcs-montages-simulation/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_tdcs-montages-simulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Complex Span</title>
      <link>https://clinicalbrainlab.github.io/software/complexspan/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/complexspan/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/neuropsychology/ComplexSpan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Complex Span&lt;/a&gt; is a 
&lt;a href=&#34;https://www.psychopy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PsychoPy&lt;/a&gt; implementation of a working memory span task, adapted from 
&lt;a href=&#34;https://link.springer.com/article/10.3758/s13428-015-0566-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gonthier et al. (2015)&lt;/a&gt;.
Working memory is a critical component of human cognition and can be defined as the ability to store and process information simultaneously.&lt;/p&gt;
&lt;p&gt;The task comprises of 2 components, the simple span and the complex span.
The simple span portion presents to-be-remembered consonants, where participants are prompted to type in the correct verbatim recall as each set size increases.
The complex span portion interleaves processing and recall tasks, where open-ended arithmetic operations are presented before to-be-recalled consonants are presented as each set size increases.&lt;/p&gt;
&lt;h2 id=&#34;application&#34;&gt;Application&lt;/h2&gt;
&lt;p&gt;Complex Span is currently used in our lab to supplement the analysis of behavioural and neurocognitive correlates in the 
&lt;a href=&#34;https://clinicalbrainlab.github.io/project/deception/&#34;&gt;Deception Project&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Lau, Z. J., Pham, T. T., Makowski, D., &amp;amp; S H Chen, A. (2019). A Psychopy Implementation of the Complex Span for Working Memory Assessment. Retrieved from 
&lt;a href=&#34;http://doi.org/10.5281/zenodo.3529329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://doi.org/10.5281/zenodo.3529329&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>E-Prime</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/eprime/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/eprime/</guid>
      <description>&lt;h2 id=&#34;what-is-e-prime&#34;&gt;What is E-Prime?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://pstnet.com/products/e-prime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;E-Prime®&lt;/a&gt; is a software with a graphical interface for creating experiments in behavioural research. It accommodates text, image, video, and audio stimuli, as well as multiple choice options.
The data is exported in a text file and is compatible with SPSS, R, and Excel.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at Clinical Brain Lab make use of E-Prime to create cognitive experiments, such as to test bilingual abilities in participants.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Electroencephalogram</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/eeg/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/eeg/</guid>
      <description>&lt;h2 id=&#34;what-is-eeg&#34;&gt;What is EEG?&lt;/h2&gt;
&lt;p&gt;EEG (Electroencephalogram) is a neuroimaging technique used to measure electrical activity at the scalp that reflects the neural activity in the brain. It is a real-time recording of neural activity with millisecond temporal resolution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/EEG_Recording.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-an-eeg-done&#34;&gt;How is an EEG Done?&lt;/h2&gt;
&lt;p&gt;EEG is a completely safe and non-invasive technique. There is no exposure to any form of external x-rays or radiation. To record the EEG signals, an EEG cap would be put over the head and connected to an amplifier which would allow us to see the brain waves on a computer screen.
Electrolytic gel is inserted into the small plastic holders in the cap to improve the conductance between the electrodes and the scalp.
Separate electrodes may also be directly attached to the skin (such as above and below the eyes) using electrode tape.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/IMG-20150628-WA0008.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-eeg-used-for&#34;&gt;What is EEG used for?&lt;/h2&gt;
&lt;p&gt;At the Clinical Brain Lab NTU, we are using EEG to measure changes in brain activity after cognitive training or during cognitive tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional Magnetic Resonance Imaging</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/fmri/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/fmri/</guid>
      <description>&lt;h2 id=&#34;what-is-fmri&#34;&gt;What is fMRI?&lt;/h2&gt;
&lt;p&gt;fMRI is a safe, noninvasive imaging technology. Unlike x-rays, which use ionizing radiation, fMRI images are generated from a strong magnetic field and low-power radio-waves.
Therefore, there is no risk of exposure to radiation in fMRI.&lt;/p&gt;
&lt;h2 id=&#34;why-use-fmri&#34;&gt;Why use fMRI?&lt;/h2&gt;
&lt;p&gt;fMRI allows researchers to obtain images of brain activity over time, as participants complete various tasks.
From these images, researchers get a better understanding of the brain areas that are involved in the tasks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/3TMRI_aging.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional Near-Infrared Spectroscopy</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/fnirs/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/fnirs/</guid>
      <description>&lt;h2 id=&#34;what-is-fnirs&#34;&gt;What is fNIRS?&lt;/h2&gt;
&lt;p&gt;fNIRS (functional near-infrared spectroscopy) is a non-invasive neuroimaging technique that measures brain responses by recording changes in the amount of oxygenated/deoxygenated blood.
It works based on the principle of light scattering – the device sends high intensity beams of near-infrared light at the scalp and detects changes to amount of light absorbed within the brain.
Mathematical algorithms are then applied to process the collected data to calculate changes in oxygenated/deoxygenated haemoglobin concentration. These changes are associated with changes in brain function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/fNIRS2.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-fnirs-done&#34;&gt;How is fNIRS Done?&lt;/h2&gt;
&lt;p&gt;fNIRS is a non-invasive neuroimaging technique that does not require any exposure to radiation or x-rays. To record signals, a fNIRS cap is fitted over the participant’s head.
The optodes (sources and detectors) are then attached onto the cap. To ensure the optodes sit directly on the scalp, the participant’s hair may be moved to the side.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/fNIRS3.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-fnirs-used-for&#34;&gt;What is fNIRS used for?&lt;/h2&gt;
&lt;p&gt;Currently in our lab, we are using fNIRS to explore changes in brain activity during brain stimulation and during cognitive tasks – i.e. reading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeuroKit2</title>
      <link>https://clinicalbrainlab.github.io/software/neurokit2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/neurokit2/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/software/neurokit.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroKit2&lt;/a&gt; is a 
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; Toolbox for Neurophysiological Signal Processing.
Led by 
&lt;a href=&#34;https://clinicalbrainlab.github.io/author/dominique-makowski/&#34;&gt;Dr. Dominique Makowski&lt;/a&gt;, NeuroKit2 is designed to be an open-source, community-driven, and user-centered Python package dedicated to advanced biosignal processing routines.
These bodily signals include electrocardiogram (ECG), electrodermal activity (EDA), respiration (RSP), electromyography (EMG), and electrooculography (EOG).
Researchers and clinicians without extensive knowledge of programming or biomedical signal processing can analyze physiological data with a few lines of code.&lt;/p&gt;
&lt;p&gt;The package consists of comprehensive 
&lt;a href=&#34;https://neurokit2.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; which provides some guidelines on getting started with Python and some tutorials on data analysis.
Its functionalities include signal simulation, data management (e.g., downloading existing datasets, reading and formatting files into a dataframe), events extraction from signals, epochs extraction, signal processing (e.g., filtering, resampling, rate computation),
spectral analyses, complexity and entropy analyses, convenient statistical methods (e.g., K-means clustering, ICA or PCA).
Convenient plotting functions are also available, allowing for quick visualization of processed signals.&lt;/p&gt;
&lt;h2 id=&#34;application&#34;&gt;Application&lt;/h2&gt;
&lt;p&gt;NeuroKit2 is currently used in our lab to analyze neurophysiological correlates of deception in the 
&lt;a href=&#34;https://clinicalbrainlab.github.io/project/deception/&#34;&gt;Deception Project&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Makowski, D., Pham, T., Lau, Z. J., Brammer, J. C., Lesspinasse, F., Pham, H., Schölzel, C., &amp;amp; S H Chen, A. (2020). NeuroKit2: A Python Toolbox for Neurophysiological Signal Processing. Retrieved March 28, 2020, from 
&lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/neuropsychology/NeuroKit&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD fellowships</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_phd2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_phd2/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are currently actively recruiting for PhD students interested in developing research in educational neuroscience, affective neuroscience and aging neuroscience (specifically in older neurological patients).&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;Research in the lab is focused on the neural basis of higher cognition in the cerebellum, cognitive training in healthy aging and we will be developing an area in Educational Neuroscience. Main research modalities in our lab include: neuropsychological assessments, cognitive tests, functional Magnetic Resonance (fMRI), diffusion MRI (DTI, HARDI, DSI), EEG and Transcranial Magnetic Stimulation (TMS). The candidate will be expected to conduct research in areas noted above, especially using diffusion MRI. However, he/she is also encouraged to develop own related research topic of interest. For more information about the lab please click 
&lt;a href=&#34;http://portal.hss.ntu.edu.sg/annalab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;looking-for&#34;&gt;Looking For&lt;/h2&gt;
&lt;p&gt;We welcome applicants with a &lt;strong&gt;Bachelors&lt;/strong&gt; or &lt;strong&gt;Masters degree&lt;/strong&gt; in various backgrounds such as: &lt;strong&gt;experimental psychology, biopsychology, cognitive psychology, neuropsychology, neurology, psychiatry, cognitive neuroscience, electrical engineering, medical engineering, computer science&lt;/strong&gt;, and related fields.&lt;/p&gt;
&lt;p&gt;The successful applicant will be enrolled in the graduate psychology program by research. Competitive scholarships may be applied through the Graduate Psychology Program or the Interdisciplinary Graduate Program with CRADLE@NTU (CRADLE-IGP). For non-local degree holders, GRE exams (general and subject) will be required for application. Find out more about the 
&lt;a href=&#34;https://www.ntu.edu.sg/education/graduate-programme/ph.d.-in-psychology&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graduate Psychology Program&lt;/a&gt; and 
&lt;a href=&#34;https://www.ntu.edu.sg/cradle/home/interdisciplinary-graduate-programme-%28igp%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GRADLE-IGP&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;Please address questions or send Curriculum Vita to 
&lt;a href=&#34;mailto:annabelchen@ntu.edu.sg&#34;&gt;annabelchen@ntu.edu.sg&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pyllusion</title>
      <link>https://clinicalbrainlab.github.io/software/pyllusion/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/pyllusion/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/software/pyllusion.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/RealityBending/Pyllusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pyllusion&lt;/a&gt; is a 
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; Toolbox that utilizes a parametric framework to generate visual illusions.&lt;/p&gt;
&lt;p&gt;The parametric approach implemented in this software proposes to describe illusions using a set of parameters, such as for instance the difference in the target features, and the strength of the contextual information in biasing the perception of the illusion (i.e., illusion strength). These two parameters can be modulated independently in &lt;em&gt;Pyllusion&lt;/em&gt; to investigate the precision and threshold at which certain populations become susceptible to the illusion. The aim of &lt;em&gt;Pyllusion&lt;/em&gt; is to foster reproducible science, allowing neuroscientists to easily report, generate and manipulate similar stimuli regardless of the display format and software. There is comprehensive 
&lt;a href=&#34;https://realitybending.github.io/Pyllusion/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; regarding the functionalities of &lt;em&gt;Pyllusion&lt;/em&gt; and code examples of how illusions can be generated in the form of images and psychopy stimuli.&lt;/p&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;p&gt;Pyllusion was presented at the &lt;strong&gt;43rd European Conference on Visual Perception (ECVP)&lt;/strong&gt;, held from 22 to 27 August 2021. A video walkthrough of the poster is available via this 
&lt;a href=&#34;https://www.youtube.com/watch?v=uptP_NxEHaM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube link&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Makowski, D., Lau, Z. J., Pham, T., Boyce, P., S H Chen, A. (in preparation). Pyllusion: A Parametric Framework to Generate Visual Illusions using Python.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/python/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/python/</guid>
      <description>&lt;h2 id=&#34;what-is-python&#34;&gt;What is Python?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; is general-purpose, free and open-source programming language for both software developers and researchers.
It is becoming increasingly 
&lt;a href=&#34;https://www.apa.org/science/about/psa/2019/07/python-research&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;popular amongst psychology researchers&lt;/a&gt;, allowing
researchers to create experiments, pre-process and clean data, as well as conduct statistical analyses and graphical visualization.&lt;/p&gt;
&lt;h2 id=&#34;building-experiments&#34;&gt;Building Experiments&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.psychopy.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PsychoPy&lt;/a&gt; is a Python package that has been used amongst psychology and neuroscientists to run cognitive experiments.
Not only does it comprise of a graphical user interface (GUI) so that novices can easily create simple experiments, more advanced customization can be included using Python code.&lt;/p&gt;
&lt;h2 id=&#34;data-wrangling&#34;&gt;Data Wrangling&lt;/h2&gt;
&lt;p&gt;Base Python consists of a series of modules that accommodates different functionalities. For example, the 
&lt;a href=&#34;https://pandas.pydata.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pandas&lt;/a&gt; module allows for importing, manipulation and organization of
text files, csv (comma-separated-values) files, or excel spreadsheets. The 
&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scipy&lt;/a&gt; module is also made for statistical analyses, and 
&lt;a href=&#34;https://matplotlib.org/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matplotlib&lt;/a&gt;
for graphical visualization of data.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at Clinical Brain Lab use Python to analyze EEG and physiological (e.g., ECG, EDA, respiration, EMG, EOG) data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/r/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/r/</guid>
      <description>&lt;h2 id=&#34;what-is-r&#34;&gt;What is R?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.r-project.org/about.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R&lt;/a&gt; is a free programming language and software environment that comprises of a suite of pre-processing abilities (e.g., data manipulation
and cleaning), statistical analyses and modelling, and graphical visualization.&lt;/p&gt;
&lt;h2 id=&#34;most-ideal-for&#34;&gt;Most Ideal For&lt;/h2&gt;
&lt;p&gt;Behavioural Data&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at the Clinical Brain Lab use R extensively to pre-process behavioural data and conduct statistical analyses e.g., factor analysis, linear mixed effects models. We have also used it to host presentations!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Information for Parents and Kids</title>
      <link>https://clinicalbrainlab.github.io/resources/info/for_parents/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/info/for_parents/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://blogs.ntu.edu.sg/reading/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/info/SoRblog.png&#34; alt=&#34;png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;From research to practice, we communicate latest research findings, share suggestions for positive reading based on what we know, to cultivate interest for reading in children. Click 
&lt;a href=&#34;https://blogs.ntu.edu.sg/reading/welcome/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; to visit our blog.&lt;/p&gt;
&lt;p&gt;Learn more about Reading by exploring our blog:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://blogs.ntu.edu.sg/reading/category/science-of-reading/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Science of Reading - Sharing what we know about reading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://blogs.ntu.edu.sg/reading/category/tips-for-parents-caregivers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tips for Reading - Based on what we know, we share suggestions for positive reading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://blogs.ntu.edu.sg/reading/category/read-and-play/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reading recommendations - Cultivating interest in reading through reading materials&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We upload new posts every last Wednesday of the month, join us as we explore the fun in reading!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SATA</title>
      <link>https://clinicalbrainlab.github.io/software/sata/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/sata/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/ClinicalBrainLab/SATA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SATA&lt;/a&gt; is a Matlab Based toolbox that works well with Matlab version 2017 and above.
However, we have not tested SATA for other MATLAB versions. SATA works on Windows, Linux and Mac. SATA is a post-processing toolbox after the tDCS montages have been simulated in COMETS or ROAST. To download the Graphical user interface (GUI) version of SATA, please visit 
&lt;a href=&#34;https://doi.org/10.21979/N9/DMWPZK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.21979/N9/DMWPZK&lt;/a&gt;. The SATA GUI package will allow the users to simulate the chosen montages in either COMETS or ROAST, and obtain the post-processed simulation outputs from SATA. Further, you may wish to not use the SATA GUI.
In this case, you can download the codes from the 
&lt;a href=&#34;https://github.com/ClinicalBrainLab/SATA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.
However, you will need to download SPM, Fieldtrip, and Talairach client (do add them to matlab path). Similarly, you will have to run COMETS or ROAST separately to generate simulation outputs.So please do download them from their respective websites and see how to use them from their manuals. For details on using the code of SATA, please refer the SATA MANUAL (section 3.4).&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Bhattacharjee, S., Kashyap, R., Rapp, B., Oishi, K., Desmond, J., &amp;amp; Chen, S. (2019). Simulation Analyses of tDCS Montages for the Investigation of Dorsal and Ventral Pathways. Scientific Reports (in press) doi: DOI: 10.1038/s41598-019-47654-y&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SPM</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/spm/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/spm/</guid>
      <description>&lt;h2 id=&#34;what-is-spm&#34;&gt;What is SPM?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.fil.ion.ucl.ac.uk/spm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPM&lt;/a&gt; or Statistical Parametric Mapping is a software package to analyze brain imaging sequences. It is designed to analyze data obtained from
fMRI, PET, SPECT, EEG and MEG.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at the Clinical Brain Lab make use of SPM to analyze fMRI data when analyzing reading networks in bilingualism, as well as the neural correlates of deception.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial Direct Current Stimulation</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/tdcs/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/tdcs/</guid>
      <description>&lt;h2 id=&#34;what-is-tdcs&#34;&gt;What is tDCS?&lt;/h2&gt;
&lt;p&gt;tDCS (Transcranial Direct Current Stimulation) is a non-invasive and relatively painless brain stimulation technique that adjusts regional brain activity through modulating the transmembrane potential of neurons by sending low amplitude direct-current into the scalp.
In healthy populations, anodal tDCS has been shown to increase cortical excitability while cathodal tDCS has been shown to inhibit cortical excitability.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/tDCS.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-tdcs-done&#34;&gt;How is tDCS Done?&lt;/h2&gt;
&lt;p&gt;The electrode to be used is inserted into saline soaked sponges. The region where the electrode is to be placed is first wiped clean with alcohol wipes. Hair is then parted and the sponge is positioned over the marked position and secured in place using rubber straps.
When ready, the experimenter uses the DC-stimulator to start the stimulation.&lt;/p&gt;
&lt;h2 id=&#34;what-is-tdcs-used-for&#34;&gt;What is tDCS used for?&lt;/h2&gt;
&lt;p&gt;Currently in our lab, we are investigating effects of tDCS on cognitive tasks (e.g. reading) and exploring changes in brain activity as a result of tDCS using fNIRS.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial Magnetic Stimulation</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/tms/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/tms/</guid>
      <description>&lt;h2 id=&#34;what-is-tms&#34;&gt;What is TMS?&lt;/h2&gt;
&lt;p&gt;TMS (Transcranial Magnetic Stimulation) is a non-invasive and painless tool that modulates neural activity. It works on the principle of Faraday’s law of electromagnetic induction.
In TMS, an electromagnetic coil sends a perpendicular magnetic field into the region of interest on the scalp. This field indirectly influences neuronal activity. TMS has been shown in some cases to induce cortical excitability and in some cases to depress excitability.
TMS can be administered in bursts at a rhythmic frequency (repetitive TMS) or as a single pulse. Repetitive TMS has been shown to have a greater and lasting effect. Depending on the question, rapid or slow repetitive TMS can be administered.&lt;/p&gt;
&lt;h2 id=&#34;how-is-tms-done&#34;&gt;How is TMS Done?&lt;/h2&gt;
&lt;p&gt;An electromyography (EMG) module is first attached via a wristband and by pasting electrodes onto the participant.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/TMS1.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;After setting up the parameters, an experimenter positions the magnetic coil above the participant’s scalp, over the region of interest. When activated, a high-current pulse is produced in the TMS coil, inducing a perpendicular magnetic field.
As high-current pulses are sent through the coil, the participant may hear clicks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/TMS2.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-tms-used-for&#34;&gt;What is TMS used for?&lt;/h2&gt;
&lt;p&gt;TMS can be used to treat clinical conditions (such as drug-resistant depression) or be used as an experimental technique to understand brain functions. In our lab, we are applying fMRI-guided TMS to target regions of the brain to determine its involvement in various cognitive networks.
We are also combining it with EEG to understand neuroplasticity.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://clinicalbrainlab.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cerebro-cerebellar pathways for verbal working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_cerebellum-working-memory-pathways/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_cerebellum-working-memory-pathways/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2018</title>
      <link>https://clinicalbrainlab.github.io/talk/2018_brainconnects/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2018_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2018/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2018.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working memory, age and education: A lifespan fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-education/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-education/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Functional connectivity of resting-state, working memory and inhibition networks in perceived stress</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_stress-working-memory/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_stress-working-memory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The role of regional heterogeneity in age-related differences in functional hemispheric asymmetry: an fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-asymmetry/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-asymmetry/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2017</title>
      <link>https://clinicalbrainlab.github.io/talk/2017_brainconnects/</link>
      <pubDate>Tue, 22 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2017_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2017/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2017.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Frontal-subcortical circuitry in social attachment and relationships: A cross-sectional fMRI ALE meta-analysis</title>
      <link>https://clinicalbrainlab.github.io/publication/2017_meta-analysis-hot-cool/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2017_meta-analysis-hot-cool/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2016</title>
      <link>https://clinicalbrainlab.github.io/talk/2016_brainconnects/</link>
      <pubDate>Fri, 23 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2016_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2016/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2016.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reconciling individual differences with collective needs: The juxtaposition of sociopolitical and neuroscience perspectives on remediation and compensation of student skill deficits</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_learning-remediation-compensation/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_learning-remediation-compensation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modality specificity in the cerebro-cerebellar neurocircuitry during working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-modality/</link>
      <pubDate>Sun, 15 May 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-modality/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Higher Cognition &amp; the Cerebellum</title>
      <link>https://clinicalbrainlab.github.io/project/cerebellum/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/cerebellum/</guid>
      <description>&lt;p&gt;Cerebellum has increasingly been recognized for its contributions beyond motor control to higher cognitive functions. Our work focuses on the roles of cerebellum in working memory, i.e., the ability to hold information in short-term memory. We use neuroimaging techniques to examine the structural and functional connectivity of the cerebro-cerebellar pathways for verbal and visual working memory.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Research Output:&lt;/u&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2016_cerebellum-working-memory-dynamics/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Temporal dynamics of visual working memory.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2016_cerebellum-working-memory-modality/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modality specificity in the cerebro-cerebellar neurocircuitry during working memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2019_cerebellum-working-memory-pathways/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cerebro-cerebellar pathways for verbal working memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2022_cerebellar-tms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cerebellar Transcranial Magnetic Stimulation (TMS) Impairs Visual Working Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Publication:&lt;/b&gt; 
&lt;a href=&#34;https://www.clinicalbrain.org/publication/2021_cerebellum-ocd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Individual-fMRI-approaches reveal cerebellum and visual communities to be functionally connected in obsessive compulsive disorder&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>A comprehensive analysis of connectivity and aging over the adult life span</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-connectivity/</link>
      <pubDate>Mon, 14 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-connectivity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Temporal dynamics of visual working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-dynamics/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-dynamics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2015</title>
      <link>https://clinicalbrainlab.github.io/talk/2015_brainconnects/</link>
      <pubDate>Fri, 31 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2015_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2nd/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2015.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BrainConnects 2014</title>
      <link>https://clinicalbrainlab.github.io/talk/2014_brainconnects/</link>
      <pubDate>Fri, 01 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2014_brainconnects/</guid>
      <description>







  
  


&lt;div class=&#34;gallery&#34;&gt;

  
  
  
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_group_1_2.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_group_1_2_hu9c1b6e0e5fd15c5d80344f1f32ec78bb_160480_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;261&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_nitish@.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_nitish@_huf92ead520f43847e8e6052e20a75e8e9_127385_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;311&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_workshopclosingremarks1.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_workshopclosingremarks1_hub99cf81edab8a7224763508ad4c16a20_120048_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;299&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  

  
&lt;/div&gt;
&lt;!-- TODO: fix broken link --&gt;
&lt;!-- Please click [here](https://clinicalbrain.org/events/brainconnects/Brain%20Connects%202014%20Workshop%20Program.pdf) for the workshop outline. --&gt;
&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/view/brainconnects2014/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2014.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
