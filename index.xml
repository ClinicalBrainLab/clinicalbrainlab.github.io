<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Clinical Brain Lab</title>
    <link>https://clinicalbrainlab.github.io/</link>
      <atom:link href="https://clinicalbrainlab.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>The Clinical Brain Lab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 28 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://clinicalbrainlab.github.io/images/icon_hu30d0ad82a56c1708370149d7b9443316_148842_512x512_fill_lanczos_center_3.png</url>
      <title>The Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/</link>
    </image>
    
    <item>
      <title>Young Adults Needed</title>
      <link>https://clinicalbrainlab.github.io/post/role-play/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/role-play/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./Role-play.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Part-time Student Assistant Position at The Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_part-time-ra/</link>
      <pubDate>Fri, 11 Feb 2022 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_part-time-ra/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Clinical Brain Lab, led by Principal Investigator Prof. Annabel Chen, is looking to hire 3 part-time undergraduate research assistants (10 hours/week) to assist with the recruitment and data collection of two neuroimaging studies.&lt;/p&gt;
&lt;p&gt;You will be part of a dynamic team of researchers who are using cutting-edge functional near-infrared spectroscopy (fNIRS) and magnetic resonance imaging (MRI) to investigate the brain and behaviour of adults and children when presented with different Singaporean cultural stimuli.&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;Depending on your goals for joining us, you will be involved in some of the following activities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Administrative support for recruitment and screening of participants&lt;/li&gt;
&lt;li&gt;Assist with data collection using fNIRS and MRI equipment&lt;/li&gt;
&lt;li&gt;Assist with contacting participants and collating questionnaire responses&lt;/li&gt;
&lt;li&gt;Data preprocessing of MRI and fNIRS datasets&lt;/li&gt;
&lt;li&gt;Other activities that support the research studies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You must be a current undergraduate student at Nanyang Technological University (NTU)&lt;/li&gt;
&lt;li&gt;Fast learner and eager to acquire advanced neuroimaging data collection skills&lt;/li&gt;
&lt;li&gt;Ability to work on some weekends (for data collection)&lt;/li&gt;
&lt;li&gt;Previous experience in neuroimaging research is an advantage&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;If you are interested in this job opening, please contact:&lt;/p&gt;
&lt;p&gt;Principal Investigator: Prof. Annabel Chen Shen-Hsing
Tel: +65 6908 1457
Email:annabelchen@ntu.edu.sg&lt;/p&gt;
&lt;p&gt;Research Fellow: Dr. Atiqah Azhari
Email:nuratiqah.azhari@ntu.edu.sg&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calling for Submissions to Special Issue &#34;Brain Activity Monitoring and Measurement&#34;</title>
      <link>https://clinicalbrainlab.github.io/talk/2021_submission_sensors/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2021_submission_sensors/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://www.mdpi.com/journal/sensors/special_issues/BAMM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link for more information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sex difference in tDCS current mediated by changes in cortical anatomy: A study across young, middle and older adults</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_sex-differences-tdcs/</link>
      <pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_sex-differences-tdcs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2021</title>
      <link>https://clinicalbrainlab.github.io/talk/2021_brainconnects/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2021_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;http://thebrainx.com/brainconnects2021/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2021.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research Assistant Position at The Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_research-assistant/</link>
      <pubDate>Wed, 06 Oct 2021 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_research-assistant/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Clinical Brain Laboratory within the School of Social Sciences seeks applications for the position of Research Assistant. The Research Assistant will be an integral member of an inter-disciplinary research lab developing multimodal methodologies for non-invasive brain stimulation and neurophysiology to measure neural adaptations to cognitive-motor training intervention.&lt;/p&gt;
&lt;p&gt;The successful candidate will be responsible for overseeing the day-to-day operations of research projects. This position requires task-orientation, excellent organizational skills, attention to details and accuracy, flexibility in responding to fluid situations, good interpersonal skills, as well as the ability to work independently. The main research modalities in our lab include neuropsychological assessments, cognitive tests, functional Magnetic Resonance (fMRI), diffusion MRI (DTI, HARDI, DSI), electroencephalography (EEG), Transcranial Magnetic Stimulation (TMS).&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Day to day coordination of funded projects.&lt;/li&gt;
&lt;li&gt;Preparation of ethics documents to institutional review boards.&lt;/li&gt;
&lt;li&gt;Participant recruitment.&lt;/li&gt;
&lt;li&gt;Data collection using multimodal neuromodulation and neurophysiological recordings, such as electroencephalography and transcranial magnetic stimulation&lt;/li&gt;
&lt;li&gt;Liaise with stakeholders and project collaborators.&lt;/li&gt;
&lt;li&gt;Systems administration, including maintenance of network servers and data security.&lt;/li&gt;
&lt;li&gt;Contribute to the production of research reports.&lt;/li&gt;
&lt;li&gt;Perform other tasks as required by the Principal Investigators relevant to the research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bachelors (Honours) degree in Psychology, Cognitive Neuroscience or related field from University of good standing.&lt;/li&gt;
&lt;li&gt;Experience with neuromodulation and/or neurophysiological techniques such as; transcranial magnetic stimulation, transcranial direct-current stimulation, electroencephalography and/or functional near-infrared spectroscopy is preferred.&lt;/li&gt;
&lt;li&gt;Good project coordination and administration skills, including data management and storage.&lt;/li&gt;
&lt;li&gt;Strong oral and written communication skills.&lt;/li&gt;
&lt;li&gt;Excellent organizational skills and able to work within given deadlines.&lt;/li&gt;
&lt;li&gt;Self-directed learner who effectively picks up relevant skills as needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;To apply, please send Curriculum Vitae, letter of application with research interests, and three letters of recommendation to 
&lt;a href=&#34;mailto:annabelchen@ntu.edu.sg&#34;&gt;annabelchen@ntu.edu.sg&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contact information&lt;/strong&gt;: Professor S.H. Annabel Chen, PhD, Professor, of Psychology, School of Social Sciences, Nanyang Technological University, 48 Nanyang Drive, SHHK-04-19, Singapore 639818, phone +65-6316-8836&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Focality-Oriented Selection of Current Dose for Transcranial Direct Current Stimulation</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_tdcs-dtdi/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_tdcs-dtdi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain Entropy, Fractal Dimensions and Predictability: A Review of Complexity Measures for EEG in Healthy and Neuropsychiatric Populations</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_braincomplexity/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_braincomplexity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Part-time System Administration Position at The Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_system-admin/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_system-admin/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Clinical Brain Lab housed within the Division of Psychology at NTU is seeking a part-time system administrator to help with setting up and maintaining networked servers used for image analyses within the lab. The main research focus of the lab is studying brain functions using neuroimaging methods.&lt;/p&gt;
&lt;p&gt;The Clinical Brain Lab is currently involved in various projects in neuroimaging and technological applications in education. The  position will allow acquisition of research experience in this field if the applicant has related interest.&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;This is an hourly position of 8-10 hours per week (negotiable). The duties of this position include the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluate and install software packages on behalf of users.&lt;/li&gt;
&lt;li&gt;Manage software licenses (E.g. CALs, Matlab etc)&lt;/li&gt;
&lt;li&gt;Ensure QoS and security for servers. (Security design and implementation)&lt;/li&gt;
&lt;li&gt;Upgrading and patching server operating systems.&lt;/li&gt;
&lt;li&gt;Plan and manage storage life cycle, including backups.&lt;/li&gt;
&lt;li&gt;Evaluating software for future deployment.&lt;/li&gt;
&lt;li&gt;Troubleshoot any other software and hardware problems.&lt;/li&gt;
&lt;li&gt;Website webmaster (GitHub)&lt;/li&gt;
&lt;li&gt;Attend Weekly Lab Meetings&lt;/li&gt;
&lt;li&gt;Communicate with related IT personnel for network issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;p&gt;Graduate or undergraduate students may apply. The requirements of this position include the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experience with servers and other high availability appliances.&lt;/li&gt;
&lt;li&gt;Managing and configuring network services (E.g. VPN, routing, channel bonding etc).&lt;/li&gt;
&lt;li&gt;Troubleshooting FlexNET license manager, remote desktop license manager.&lt;/li&gt;
&lt;li&gt;Proficiency in RAID and Network file systems (iSCSI LUN, Targets, CIFS)&lt;/li&gt;
&lt;li&gt;Knowledge in web services (Apache, MySQL, FTP)&lt;/li&gt;
&lt;li&gt;Design and implementation of Hypervisors and virtualization (E.g. ESXI, resource pools, virtual switches)&lt;/li&gt;
&lt;li&gt;Matlab, R, C++ and Scripting (Windows PowerShell, or bash/tcsh)&lt;/li&gt;
&lt;li&gt;Familiar with Windows 2008 R2, 2012, CentOS environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;If you have the suitable qualifications and are interested, please send detailed CV and inquiry to 
&lt;a href=&#34;mailto:annabelchen@ntu.edu.sg&#34;&gt;annabelchen@ntu.edu.sg&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contact information&lt;/strong&gt;: Professor S.H. Annabel Chen, PhD, Professor, of Psychology, School of Social Sciences, Nanyang Technological University, 48 Nanyang Drive, SHHK-04-19, Singapore 639818, phone +65-6316-8836&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Parametric Framework to Generate Visual Illusions using Python</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_pyllusion/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_pyllusion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heart Rate Variability in Psychology: A Review of HRV Indices and an Analysis Tutorial</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_hrv/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_hrv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Structure of Deception: Validation of the Lying Profile Questionnaire</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_deception-scale/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_deception-scale/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NeuroKit2: A Python toolbox for neurophysiological signal processing</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_neurokit/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_neurokit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Individual-fMRI-approaches reveal cerebellum and visual communities to be functionally connected in obsessive compulsive disorder</title>
      <link>https://clinicalbrainlab.github.io/publication/2021_cerebellum-ocd/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2021_cerebellum-ocd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aging patterns of Japanese auditory semantic processing: an fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_ageing-adutiroy-processing/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_ageing-adutiroy-processing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading proficiency influences the effects of transcranial direct current stimulation: Evidence from selective modulation of dorsal and ventral pathways of reading in bilinguals</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_learning-biliteracy-tdcs/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_learning-biliteracy-tdcs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Opportunities at Centre for Lifelong Learning and Individualised Cognition (CLIC)</title>
      <link>https://clinicalbrainlab.github.io/join/join_clic_postdoc/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_clic_postdoc/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Centre for Lifelong Learning and Individualised Cognition (CLIC)&lt;/strong&gt;, funded by the 
&lt;a href=&#34;https://www.nrf.gov.sg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;National Research Foundation (NRF)&lt;/a&gt; in Singapore and coordinated through the 
&lt;a href=&#34;https://www.create.edu.sg/about-create/research-centres/cares&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cambridge Centre for Advanced Research and Education in Singapore (CARES)&lt;/a&gt;, is a collaboration between Nanyang Technological University (NTU) and the University of Cambridge. CLIC is a flagship programme in the Science of Learning to harness advancements in neuroscience to develop &lt;strong&gt;cognitive training programmes&lt;/strong&gt; for the improvement of &lt;strong&gt;lifelong flexible learning&lt;/strong&gt;, focusing initially on adolescents and young adults, but also envisaging work with infants and older adults. This is a strategic global initiative for the Universities of Cambridge and NTU that brings together multidisciplinary expertise from over 30 investigators in the areas of Neuroscience, Psychology, Linguistics and Education across the two universities.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.ntu.edu.sg/Pages/home.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nanyang Technological University&lt;/a&gt; is a research intensive university currently ranked 13th globally and placed 1st amongst the world’s best young universities. The University has Colleges of Engineering, Business, Science, Humanities, Arts, &amp;amp; Social Sciences, and an Interdisciplinary Graduate School. Further, the new Lee Kong Chian School of Medicine benefits from a dual campus located at Novena, in close proximity to the Singapore city centre. The Cognitive Neuroimaging Centre (CoNiC) houses state-of-the-art neuroimaging facilities including a newly installed 3T MRI scanner and MEG, as well as new EEG, NIRS, TMS and tDCS equipment.&lt;/p&gt;
&lt;p&gt;The first phase of the CLIC program will initially be housed at Nanyang Technological University, Singapore. As the programme progresses, other sites will be developed to meet the needs of the experimental programme. The new CLIC research centre will provide a vibrant, fast-paced, international and interdisciplinary environment with excellent opportunities for skills development and knowledge exchange between partner Principal Investigator labs in Singapore and Cambridge.&lt;/p&gt;
&lt;p&gt;The Principal Investigators involved in the first phase of the research programme include: &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;From Cambridge:&lt;/strong&gt; Director Professor Zoe Kourtzi (Psychology), Senior Scientific Advisor Professor Trevor Robbins (Psychology), Deputy Directors Professor Henriette Hendriks (Linguistics), Professor Anna Vignoles (Education), and Imaging Lead - Professor John Suckling (Psychiatry); supported by co-Investigators Prof Barbara Sahakian (Psychiatry) and Dr Michelle Ellefson (Education).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;From NTU:&lt;/strong&gt;  Director Professor Annabel Chen (Psychology), Deputy Director Asst Prof Victoria Leong (Psychology), Imaging Lead - Professor Balázs Gulyas (LKCMedicine), and Principal Investigators Professor David Hung (NIE), Asst Prof Bobby Cheon (Psychology) and Assoc Prof Georgios Christopoulos (Nanyang Business School); supported by co-Investigator Dr Teo Chew Lee (NIE). &lt;/p&gt;
&lt;h2 id=&#34;list-of-available-positions&#34;&gt;List of Available Positions&lt;/h2&gt;
&lt;h3 id=&#34;research-fellow-positions&#34;&gt;Research Fellow Positions:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://cradle.ntu.edu.sg/aboutus/Documents/Research%20Fellow_Research%20Engineer%20in%20Neuroimaging%20and%20MRI%20Pulse%20Sequence%20%28RF6%29.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research Fellow/Research Engineer in Neuroimaging and MRI Pulse Sequence (RF6)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cradle.ntu.edu.sg/aboutus/Documents/Research%20Fellow%20in%20Neuroimaging%20and%20Cognition%20%28RSB%20RF3%29.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research Fellow in Neuroimaging and Cognition (RSB RF3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cradle.ntu.edu.sg/aboutus/Documents/Research%20Fellow%20in%20Neuroimaging%20and%20Intervention%20%28RSB%20RF4%29.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research Fellow in Neuroimaging and Intervention (RSB RF4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;research-assistantassociate-positions&#34;&gt;Research Assistant/Associate Positions:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://cradle.ntu.edu.sg/aboutus/Documents/Research%20Assistant_Associate%20%28RA10-12%29.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cognition &amp;amp; Neuroimaging (RA10-12)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more available positions at CLIC, please kindly visit this link: 
&lt;a href=&#34;https://cradle.ntu.edu.sg/aboutus/Pages/Centre-for-Lifelong-Learning-and-Individualised-Cognition-%28CLIC%29.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Centre for Lifelong Learning and Individualised Cognition (CLIC)&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Psychological Determinants of the Susceptibility to Fake News amidst the COVID-19 Pandemic</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_deception-covid-fakenews/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_deception-covid-fakenews/</guid>
      <description>&lt;p&gt;As the COVID-19 outbreak spreads across the globe, the world is in parallel flooded by information reporting a wide range of facts, which veracity is not always verifiable.
Indeed, it has become increasingly apparent that the COVID-19 fake news pandemic is becoming just as viral as the outbreak of the disease itself, evidenced by the need for researchers
and authorities to track the spread of misinformation. As a consequence, the Ministry of Health in Singapore has even dedicated an entire website (See here: 
&lt;a href=&#34;https://www.moh.gov.sg/covid-19/clarifications&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.moh.gov.sg/covid-19/clarifications&lt;/a&gt;) to debunk all instances of fake news.&lt;/p&gt;
&lt;h2 id=&#34;the-role-of-conspiracy-theories&#34;&gt;The Role of Conspiracy Theories&lt;/h2&gt;
&lt;p&gt;While the authorities are struggling to provide concrete explanations about the coronavirus, conspiracy theorists are quick to provide competing ones with confidence.
This has exaggerated the spread of fake news and conspiracy theories - beliefs that seek to explain the cause of an event by a hidden, wicked and unlawful scheme, without scientific support.
For instance, a theory that the new 5G technology causes the spread of coronavirus outbreak was widely circulated and peddled by conspiracy theorists.
Studies have shown that conspiracy theories are often endorsed by people who feel powerless. Their rejection of mainstream accounts and adoption of conspiracy explanations is an attempt to make sense of the world beyond their control (Swami &amp;amp; Furnham, 2010).
The uncertainties brought about by the COVID-19 pandemic might prompt people, especially individuals with higher schizotypal tendencies (characterized by suspicion, social anxiety and paranoid ideation), to engage in this sense-making mechanism, seeking alternative explanations
to regain their sense of control. People who have the tendency to adopt conspiracy theories have been found to rely more on intuition (Pennycook, Cheyne, Barr, Koehler &amp;amp; Fugelsang, 2015; Pennycook &amp;amp; Rand, 2018) and are hence more susceptible to fake news beliefs.&lt;/p&gt;
&lt;h2 id=&#34;the-role-of-emotions&#34;&gt;The Role of Emotions&lt;/h2&gt;
&lt;p&gt;In a global pandemic where the world is in a constant elevated state of anxiety, fake news beliefs can befall anyone for reasons beyond just the persistent cognitive biases that characterize conspiracist theorists.
People are often left feeling fearful and anxious due to the endless bombardment of pandemic news information, regardless of its accuracy.
Fake news on COVID-19 are especially emotionally engaging because they play on people’s helplessness by offering some miracle remedy or fueling anger towards authorities handling the situation.&lt;/p&gt;
&lt;p&gt;A research team led by Gordon Pennycook, a researcher on the psychology of misinformation, found that individuals are more likely to perceive fake news headlines as accurate when they were in an emotional state (Martel et al., 2019). At the Clinical Brain Lab, we have started research into this area during the
Circuit Breaker period. We propose that the underlying factor driving susceptibility to fake news beliefs is not just the mere presence of negative affect, but how one regulates these emotions.
This refers to the ability to control one’s emotional state, such as considering alternative interpretations of an otherwise negative situation.&lt;/p&gt;
&lt;p&gt;In the context of the COVID-19 pandemic, an important aspect of emotion regulation is being able to navigate through the uncertainties of the future. With future plans now at a standstill and emotions running high, we become less tolerant of uncertainty and feel more helpless about our circumstances.
Poor self-control makes us cognitively lazy, believing something because “it feels right” and aligned with our emotions. Fast, intuitive processing thus often takes precedence over effortful and reflective thinking, of which the latter is needed to discern whether a piece of news is real or fake (Pennycook &amp;amp; Rand, 2019).
We are thus more vulnerable to engaging in fake news than we think.&lt;/p&gt;
&lt;h2 id=&#34;our-research&#34;&gt;Our Research&lt;/h2&gt;
&lt;p&gt;As it is important to delineate the psychological determinants of the belief in fake news as part of a global effort in combating misinformation, Prof Annabel Chen together with Research Fellow Dr Dominique Makowski and research assistants (Pham Thanh Tam and Lau Zen Juen) are currently conducting an investigation into the spread of COVID-19 fake news in Singapore.
Specifically, this study seeks to examine whether the belief in conspiracy theories and one’s ability to regulate emotions are related to one’s tendency to fall prey to fake news.
This study is pre-registered at 
&lt;a href=&#34;https://osf.io/7d3xh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSF&lt;/a&gt; and currently undergoing data analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Centre for Lifelong Learning and Individualised Cognition</title>
      <link>https://clinicalbrainlab.github.io/project/clic/</link>
      <pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/clic/</guid>
      <description>&lt;p&gt;Our projects seek to make cognitive neuroscience findings accessible to educators and facilitate collaborative work between educators and researchers.
As technology and globalisation are changing the nature of labour markets and increasing the demand for high levels of skill, the need for individuals to be able to develop new skills during their working careers is becoming increasingly pressing. While there is an increased recognition of the need for flexible behavioural and transferable skills, there is currently a gap in evidence-based training programmes that can effectively support and promote cognitive flexibility across the life course.&lt;/p&gt;
&lt;p&gt;The Centre for Lifelong Learning and Individualised Cognition (CLIC) programme aims to address this gap by developing innovative research in the science of learning and translating it to educational and real-life applications across the life course. We will adopt an integrated interdisciplinary approach that marries cross-disciplinary expertise and methodologies across Cambridge and NTU to target three life periods (early years, adolescence, middle age) when flexible behaviour is critical for coping with highly changing circumstances. Working together, we aspire to provide Singapore with a competitive leading edge in the Science of Learning through its transformative theory, methodological innovation, and high-impact practical outcomes.&lt;/p&gt;
&lt;p&gt;Ongoing Project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding and promoting individual cognitive flexibility – funded by National Research Foundation, Prime Minister’s Office Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) programme.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on the CLIC programme, please visit the official webpage at this link: 
&lt;a href=&#34;https://www.cares.cam.ac.uk/research/clic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CLIC&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Active Aging Lifestyle</title>
      <link>https://clinicalbrainlab.github.io/project/ageing/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/ageing/</guid>
      <description>&lt;p&gt;Combining both cognitive and exercise training in an intervention program may be advantageous to enhance cognitive and physical functions.
However, this approach has yet to be well researched and implemented. Given the hot and humid climate and community environments (e.g., sidewalks and street traffic) in Singapore, common aerobic exercises such as walking and jogging may not be the first choice for sedentary older adults in Singapore.
Therefore, we proposed to develop an intervention program (&lt;strong&gt;ExCITE: Exercise-Cognition Integrated Training for Enhancement&lt;/strong&gt;) that incorporates both cognitive and physical exercise components that can be easily implemented and weaved into the lifestyles of our aging population.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Alumni of Clinical Brain Lab</title>
      <link>https://clinicalbrainlab.github.io/alumni/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/alumni/</guid>
      <description>&lt;p&gt;Nanyang Technological University (Singapore):
&lt;/br&gt;&lt;/br&gt;
Undergraduate Students&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amos Law&lt;/li&gt;
&lt;li&gt;Arumugam Ramaswamy&lt;/li&gt;
&lt;li&gt;Cheng Wenxuan&lt;/li&gt;
&lt;li&gt;Chia Kai Xin&lt;/li&gt;
&lt;li&gt;Chui Yingqi&lt;/li&gt;
&lt;li&gt;Dawn Lim&lt;/li&gt;
&lt;li&gt;Derric Eng&lt;/li&gt;
&lt;li&gt;Ebenezer Chan&lt;/li&gt;
&lt;li&gt;Esmond Seow&lt;/li&gt;
&lt;li&gt;Goh Jing Tian&lt;/li&gt;
&lt;li&gt;Goh Siang Loo, Serene&lt;/li&gt;
&lt;li&gt;Helen Ho&lt;/li&gt;
&lt;li&gt;Jarrad Oh&lt;/li&gt;
&lt;li&gt;Jasmine Lim&lt;/li&gt;
&lt;li&gt;Jermaine Chu&lt;/li&gt;
&lt;li&gt;Khoo Ser Wee&lt;/li&gt;
&lt;li&gt;Lean Jing Hui&lt;/li&gt;
&lt;li&gt;Leong Li An&lt;/li&gt;
&lt;li&gt;Lim Tech Yian&lt;/li&gt;
&lt;li&gt;Lin Xiaowen&lt;/li&gt;
&lt;li&gt;Low Jia Rong&lt;/li&gt;
&lt;li&gt;Mabel Ong&lt;/li&gt;
&lt;li&gt;Matthew Teo&lt;/li&gt;
&lt;li&gt;Megan Tay&lt;/li&gt;
&lt;li&gt;Michelle Mah&lt;/li&gt;
&lt;li&gt;Neo Shao Hoon&lt;/li&gt;
&lt;li&gt;Neo Yi Fang&lt;/li&gt;
&lt;li&gt;Nur Diyanah&lt;/li&gt;
&lt;li&gt;Ong Zi Yan&lt;/li&gt;
&lt;li&gt;Rachel Tham&lt;/li&gt;
&lt;li&gt;Randal Lee Zhisheng&lt;/li&gt;
&lt;li&gt;Regine Lau&lt;/li&gt;
&lt;li&gt;Samuel Chong&lt;/li&gt;
&lt;li&gt;Seanna Neo&lt;/li&gt;
&lt;li&gt;Serene Koh&lt;/li&gt;
&lt;li&gt;Sharon Chan&lt;/li&gt;
&lt;li&gt;Shee Mei Ling&lt;/li&gt;
&lt;li&gt;Stephanie Lee&lt;/li&gt;
&lt;li&gt;Tan Suan Fong&lt;/li&gt;
&lt;li&gt;Tay Shi Ying&lt;/li&gt;
&lt;li&gt;Teh Hui Chian&lt;/li&gt;
&lt;li&gt;Tony Lim&lt;/li&gt;
&lt;li&gt;Vicki Chng Wei Qi&lt;/li&gt;
&lt;li&gt;Yap Jia Yu&lt;/li&gt;
&lt;li&gt;Yeo Jia Ying&lt;/li&gt;
&lt;li&gt;Yeo Siok Peng&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graduate Students&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chan Yee Pei&lt;/li&gt;
&lt;li&gt;Eng Goi Khia&lt;/li&gt;
&lt;li&gt;Gladys Heng&lt;/li&gt;
&lt;li&gt;Kwok Fu Yu&lt;/li&gt;
&lt;li&gt;Tan Jiat Chow&lt;/li&gt;
&lt;li&gt;Wu Chiao-Yi (Joyce)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Research Fellows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adrian Galang, PhD&lt;/li&gt;
&lt;li&gt;Belle Yick, PhD&lt;/li&gt;
&lt;li&gt;Jo Archer, PhD&lt;/li&gt;
&lt;li&gt;Lee Shu Hui, PhD&lt;/li&gt;
&lt;li&gt;Liu Heng Shuang, PhD&lt;/li&gt;
&lt;li&gt;Monika Sobczak-Edmans, PhD&lt;/li&gt;
&lt;li&gt;Rajan Kashyap, PhD&lt;/li&gt;
&lt;li&gt;Tommy Ng, PhD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Research Associates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alvin Lim, MA&lt;/li&gt;
&lt;li&gt;Cathy Kao, MS&lt;/li&gt;
&lt;li&gt;Hoki Fung,  MS&lt;/li&gt;
&lt;li&gt;Ilang Kumaran Yuvadarshini,  MS&lt;/li&gt;
&lt;li&gt;Meenakshi Siddharthan,  MS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Project Officers/Research Assistants&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adhya Neshaa Nedumaran&lt;/li&gt;
&lt;li&gt;Alison Chew&lt;/li&gt;
&lt;li&gt;Gan Su Ren&lt;/li&gt;
&lt;li&gt;Lau Zen Juen&lt;/li&gt;
&lt;li&gt;Low Li Tong&lt;/li&gt;
&lt;li&gt;Marilyn Yeo&lt;/li&gt;
&lt;li&gt;Tam Pham&lt;/li&gt;
&lt;li&gt;Tan Bee Li&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interns&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elaine Teo, Intern&lt;/li&gt;
&lt;li&gt;Jonathan Tan&lt;/li&gt;
&lt;li&gt;Max Yong, Trainee RA&lt;/li&gt;
&lt;li&gt;Pavitraa Sundram, Trainee RA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;System Admin&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lua Rui Ping, PhD&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/br&gt;&lt;/br&gt;
National Taiwan University (Taiwan):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Andy Chen, MS&lt;/li&gt;
&lt;li&gt;Camilla Chen, MS&lt;/li&gt;
&lt;li&gt;Cecilia Peng, MS&lt;/li&gt;
&lt;li&gt;Ching-I Lu, MS&lt;/li&gt;
&lt;li&gt;Eva Lin, MS&lt;/li&gt;
&lt;li&gt;Evan Song&lt;/li&gt;
&lt;li&gt;Ivy Cheng, MS&lt;/li&gt;
&lt;li&gt;Jessie Huang, MS&lt;/li&gt;
&lt;li&gt;Jing-Syun (Edward) Yu&lt;/li&gt;
&lt;li&gt;Kayako Matsuo, PhD&lt;/li&gt;
&lt;li&gt;Linda Sung, MS&lt;/li&gt;
&lt;li&gt;Max Chen&lt;/li&gt;
&lt;li&gt;Naichi Ko, MS&lt;/li&gt;
&lt;li&gt;Pao-Hsiung Chiu&lt;/li&gt;
&lt;li&gt;Psyche Hou, MS&lt;/li&gt;
&lt;li&gt;Shu-Ju Yang&lt;/li&gt;
&lt;li&gt;Siny Tsang&lt;/li&gt;
&lt;li&gt;Yu-Ru Chiu, MS&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Behevioural and Neural Correlates of Deception</title>
      <link>https://clinicalbrainlab.github.io/project/deception/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/deception/</guid>
      <description>&lt;p&gt;Traditional lie detection as used in polygraph test is based on examining one&amp;rsquo;s physiological arousal (measuring skin conductance,
heart rate, and respiration) to infer lying. However, such physiological arousal may merely be reflecting anxiety and fear during a polygraph examination,
rather than lying per se.&lt;/p&gt;
&lt;p&gt;As physiological arousal could not be used to accurately infer lying, researchers are urged to further look into the mental processes related to lying.
To date, different neurophysiological signals, including functional magnetic resonance imaging (fMRI) and event-related potentials (ERP) have been studied for possible application to index deception.
Past studies have shown evidences that strongly supporting the hypothesis that deception requires the coordination of multiple cognitive processes and thus is more cognitively taxing than truth telling.
Despite the positive findings, previous studies were often criticized for not capturing lying as it exists in the real world. Indeed, majority of the experimental paradigms required participants to lie about perceptual
stimuli or memorized materials. More importantly, unlike lying in the real world, the lies generated in research labs were often not spontaneous but instructed.&lt;/p&gt;
&lt;p&gt;To increase the translational value of the research in deception and lie detection, we aim to investigate the neural correlates of lying using paradigms that can elicit lying similar to those in the real world.
In addition, we also seek to explore the structure of dispositional deception by developing and validating a short and reliable questionnaire to characterize individuals&amp;rsquo; lying patterns.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bilingual Reading Networks</title>
      <link>https://clinicalbrainlab.github.io/project/reading-network/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/reading-network/</guid>
      <description>&lt;p&gt;Our projects aim to elucidate the neurocognitive mechanisms underlying typical and impaired reading in bilinguals.
We use a combination of behavioural assessment and neuroimaging techniques to investigate the neural reading networks for bilingual readers from a variety of language profiles, across early childhood and adulthood.
Our projects will shed light on the impact of critical factors (e.g., orthographic depth of scripts, auditory perception skills) on the bilingual reading networks. Our findings will provide implications for neuroscience-informed remediation of reading difficulties for bilingual readers.&lt;/p&gt;
&lt;p&gt;Ongoing projects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Effective Biliteracy: The Impact of Script Sets on Bilingual Reading Networks for Typical and Atypical Readers - &lt;em&gt;funded by NTU-JHU Collaborative Grant&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Modulating Reading Networks -&lt;em&gt;funded by NTU-JHU Collaborative Grant&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Cognitive Science of Multilingualism In Children (COSMIC) - &lt;em&gt;funded by National Research Foundation&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Chinese-English Bilingual Children Needed</title>
      <link>https://clinicalbrainlab.github.io/post/kid-biliteracy/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/kid-biliteracy/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./Mock_MRI_flyer.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chinese-English Bilinguals Needed</title>
      <link>https://clinicalbrainlab.github.io/post/dyslexia-biliteracy/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/dyslexia-biliteracy/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./dyslexia-biliteracy-poster.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Healthy Adults Needed</title>
      <link>https://clinicalbrainlab.github.io/post/fnirs-biliteracy/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/fnirs-biliteracy/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./fNIRS-tDCS-poster.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Promoting Effective Biliteracy</title>
      <link>https://clinicalbrainlab.github.io/project/pebbles/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/pebbles/</guid>
      <description>&lt;p&gt;The project aims to develop an early screening and training programme to promote balanced bilingual development and biliteracy attainment in early childhood.
Using a multimodal approach, we will identify early neural, cognitive, and environmental predictors in preschool years for later bilingual and biliteracy development.
We will evaluate the neurocognitive effects of different training programmes on enhancing biliteracy development. The knowledge gained from the project will broaden our understanding of the neurocognitive development of language and reading networks in young bilinguals.
The findings will have significant implications for early screening and effective training for promoting balanced bilingual and biliteracy development.&lt;/p&gt;
&lt;p&gt;Ongoing project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Promoting Effective Biliteracy in Early Childhood: A Systematic Screening and Training Programme for Balanced Bilingual Development - &lt;em&gt;funded by Singapore Millennium Foundation&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Tamil-English Bilinguals Needed</title>
      <link>https://clinicalbrainlab.github.io/post/adult-biliteracy/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/post/adult-biliteracy/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./TE-biliteracy-poster.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Translating neuroscience for educators</title>
      <link>https://clinicalbrainlab.github.io/project/translate-neuro/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/translate-neuro/</guid>
      <description>&lt;p&gt;Our projects seek to make cognitive neuroscience findings accessible to educators and facilitate collaborative work between educators and researchers.
The broad goals of our research are to encourage and strengthen dialogue between researchers, practitioners and the wider community to consolidate existing knowledge and generate new hypotheses to answer real-world questions in education and learning.
To achieve these goals we utilise a range of approaches, including language translations, open database platforms, meta-analyses and meta-analytic brain connectivity modelling, data-visualisation and focus group discussions.
This work has important implications in developing educator’s brain literacy and informing teaching and learning to support the growing population of diverse child and adult learners.&lt;/p&gt;
&lt;p&gt;Ongoing Project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding functional relationships between socio-affective and neurocognitive brain networks in adults with ASD and ADHD to better inform learning for learners and educators: Towards maximising the adult learning potential&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Completed Project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.nie.edu.sg/research/projects/project/afd-07-16-zw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Developing a translating educational neuroscience clearinghouse (TENC) for the differentiated instruction of diverse learners&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>i-SATA: A MATLAB based toolbox to estimate current density generated by transcranial direct current stimulation in an individual brain</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_isata/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_isata/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The role of primary motor cortex: More than movement execution</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_m1-review/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_m1-review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Indices of effect existence and significance in the Bayesian framework</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_bayesian/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_bayesian/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Maximizing dissimilarity in resting state detects heterogeneous subtypes in healthy population associated with high substance use and problems in antisocial personality</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_rsfmri-subtypes/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_rsfmri-subtypes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2019</title>
      <link>https://clinicalbrainlab.github.io/talk/2019_brainconnects/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2019_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2019/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Translating education neuroscience for teachers</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_learning-translating/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_learning-translating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain literacy empowers educators to meet diverse learner needs</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_learning-brain-literacy/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_learning-brain-literacy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulation analyses of tDcS montages for the investigation of dorsal and ventral pathways</title>
      <link>https://clinicalbrainlab.github.io/publication/2020_tdcs-montages-simulation/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2020_tdcs-montages-simulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Complex Span</title>
      <link>https://clinicalbrainlab.github.io/software/complexspan/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/complexspan/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/neuropsychology/ComplexSpan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Complex Span&lt;/a&gt; is a 
&lt;a href=&#34;https://www.psychopy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PsychoPy&lt;/a&gt; implementation of a working memory span task, adapted from 
&lt;a href=&#34;https://link.springer.com/article/10.3758/s13428-015-0566-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gonthier et al. (2015)&lt;/a&gt;.
Working memory is a critical component of human cognition and can be defined as the ability to store and process information simultaneously.&lt;/p&gt;
&lt;p&gt;The task comprises of 2 components, the simple span and the complex span.
The simple span portion presents to-be-remembered consonants, where participants are prompted to type in the correct verbatim recall as each set size increases.
The complex span portion interleaves processing and recall tasks, where open-ended arithmetic operations are presented before to-be-recalled consonants are presented as each set size increases.&lt;/p&gt;
&lt;h2 id=&#34;application&#34;&gt;Application&lt;/h2&gt;
&lt;p&gt;Complex Span is currently used in our lab to supplement the analysis of behavioural and neurocognitive correlates in the 
&lt;a href=&#34;https://clinicalbrainlab.github.io/project/deception/&#34;&gt;Deception Project&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Lau, Z. J., Pham, T. T., Makowski, D., &amp;amp; S H Chen, A. (2019). A Psychopy Implementation of the Complex Span for Working Memory Assessment. Retrieved from 
&lt;a href=&#34;http://doi.org/10.5281/zenodo.3529329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://doi.org/10.5281/zenodo.3529329&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>E-Prime</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/eprime/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/eprime/</guid>
      <description>&lt;h2 id=&#34;what-is-e-prime&#34;&gt;What is E-Prime?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://pstnet.com/products/e-prime/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;E-Prime®&lt;/a&gt; is a software with a graphical interface for creating experiments in behavioural research. It accommodates text, image, video, and audio stimuli, as well as multiple choice options.
The data is exported in a text file and is compatible with SPSS, R, and Excel.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at Clinical Brain Lab make use of E-Prime to create cognitive experiments, such as to test bilingual abilities in participants.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Electroencephalogram</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/eeg/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/eeg/</guid>
      <description>&lt;h2 id=&#34;what-is-eeg&#34;&gt;What is EEG?&lt;/h2&gt;
&lt;p&gt;EEG (Electroencephalogram) is a neuroimaging technique used to measure electrical activity at the scalp that reflects the neural activity in the brain. It is a real-time recording of neural activity with millisecond temporal resolution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/EEG_Recording.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-an-eeg-done&#34;&gt;How is an EEG Done?&lt;/h2&gt;
&lt;p&gt;EEG is a completely safe and non-invasive technique. There is no exposure to any form of external x-rays or radiation. To record the EEG signals, an EEG cap would be put over the head and connected to an amplifier which would allow us to see the brain waves on a computer screen.
Electrolytic gel is inserted into the small plastic holders in the cap to improve the conductance between the electrodes and the scalp.
Separate electrodes may also be directly attached to the skin (such as above and below the eyes) using electrode tape.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/IMG-20150628-WA0008.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-eeg-used-for&#34;&gt;What is EEG used for?&lt;/h2&gt;
&lt;p&gt;At the Clinical Brain Lab NTU, we are using EEG to measure changes in brain activity after cognitive training or during cognitive tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional Magnetic Resonance Imaging</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/fmri/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/fmri/</guid>
      <description>&lt;h2 id=&#34;what-is-fmri&#34;&gt;What is fMRI?&lt;/h2&gt;
&lt;p&gt;fMRI is a safe, noninvasive imaging technology. Unlike x-rays, which use ionizing radiation, fMRI images are generated from a strong magnetic field and low-power radio-waves.
Therefore, there is no risk of exposure to radiation in fMRI.&lt;/p&gt;
&lt;h2 id=&#34;why-use-fmri&#34;&gt;Why use fMRI?&lt;/h2&gt;
&lt;p&gt;fMRI allows researchers to obtain images of brain activity over time, as participants complete various tasks.
From these images, researchers get a better understanding of the brain areas that are involved in the tasks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/3TMRI_aging.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional Near-Infrared Spectroscopy</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/fnirs/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/fnirs/</guid>
      <description>&lt;h2 id=&#34;what-is-fnirs&#34;&gt;What is fNIRS?&lt;/h2&gt;
&lt;p&gt;fNIRS (functional near-infrared spectroscopy) is a non-invasive neuroimaging technique that measures brain responses by recording changes in the amount of oxygenated/deoxygenated blood.
It works based on the principle of light scattering – the device sends high intensity beams of near-infrared light at the scalp and detects changes to amount of light absorbed within the brain.
Mathematical algorithms are then applied to process the collected data to calculate changes in oxygenated/deoxygenated haemoglobin concentration. These changes are associated with changes in brain function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/fNIRS2.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-fnirs-done&#34;&gt;How is fNIRS Done?&lt;/h2&gt;
&lt;p&gt;fNIRS is a non-invasive neuroimaging technique that does not require any exposure to radiation or x-rays. To record signals, a fNIRS cap is fitted over the participant’s head.
The optodes (sources and detectors) are then attached onto the cap. To ensure the optodes sit directly on the scalp, the participant’s hair may be moved to the side.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/fNIRS3.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-fnirs-used-for&#34;&gt;What is fNIRS used for?&lt;/h2&gt;
&lt;p&gt;Currently in our lab, we are using fNIRS to explore changes in brain activity during brain stimulation and during cognitive tasks – i.e. reading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeuroKit2</title>
      <link>https://clinicalbrainlab.github.io/software/neurokit2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/neurokit2/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/software/neurokit.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroKit2&lt;/a&gt; is a 
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; Toolbox for Neurophysiological Signal Processing.
Led by 
&lt;a href=&#34;https://clinicalbrainlab.github.io/author/dominique-makowski/&#34;&gt;Dr. Dominique Makowski&lt;/a&gt;, NeuroKit2 is designed to be an open-source, community-driven, and user-centered Python package dedicated to advanced biosignal processing routines.
These bodily signals include electrocardiogram (ECG), electrodermal activity (EDA), respiration (RSP), electromyography (EMG), and electrooculography (EOG).
Researchers and clinicians without extensive knowledge of programming or biomedical signal processing can analyze physiological data with a few lines of code.&lt;/p&gt;
&lt;p&gt;The package consists of comprehensive 
&lt;a href=&#34;https://neurokit2.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; which provides some guidelines on getting started with Python and some tutorials on data analysis.
Its functionalities include signal simulation, data management (e.g., downloading existing datasets, reading and formatting files into a dataframe), events extraction from signals, epochs extraction, signal processing (e.g., filtering, resampling, rate computation),
spectral analyses, complexity and entropy analyses, convenient statistical methods (e.g., K-means clustering, ICA or PCA).
Convenient plotting functions are also available, allowing for quick visualization of processed signals.&lt;/p&gt;
&lt;h2 id=&#34;application&#34;&gt;Application&lt;/h2&gt;
&lt;p&gt;NeuroKit2 is currently used in our lab to analyze neurophysiological correlates of deception in the 
&lt;a href=&#34;https://clinicalbrainlab.github.io/project/deception/&#34;&gt;Deception Project&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Makowski, D., Pham, T., Lau, Z. J., Brammer, J. C., Lesspinasse, F., Pham, H., Schölzel, C., &amp;amp; S H Chen, A. (2020). NeuroKit2: A Python Toolbox for Neurophysiological Signal Processing. Retrieved March 28, 2020, from 
&lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/neuropsychology/NeuroKit&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Information for Parents</title>
      <link>https://clinicalbrainlab.github.io/resources/info/for_parents/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/info/for_parents/</guid>
      <description>&lt;p&gt;Info for parents&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD fellowships</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_phd2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_phd2/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are currently actively recruiting for PhD students interested in developing research in educational neuroscience, affective neuroscience and aging neuroscience (specifically in older neurological patients).&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;Research in the lab is focused on the neural basis of higher cognition in the cerebellum, cognitive training in healthy aging and we will be developing an area in Educational Neuroscience. Main research modalities in our lab include: neuropsychological assessments, cognitive tests, functional Magnetic Resonance (fMRI), diffusion MRI (DTI, HARDI, DSI), EEG and Transcranial Magnetic Stimulation (TMS). The candidate will be expected to conduct research in areas noted above, especially using diffusion MRI. However, he/she is also encouraged to develop own related research topic of interest. For more information about the lab please click 
&lt;a href=&#34;http://portal.hss.ntu.edu.sg/annalab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;looking-for&#34;&gt;Looking For&lt;/h2&gt;
&lt;p&gt;We welcome applicants with a &lt;strong&gt;Bachelors&lt;/strong&gt; or &lt;strong&gt;Masters degree&lt;/strong&gt; in various backgrounds such as: &lt;strong&gt;experimental psychology, biopsychology, cognitive psychology, neuropsychology, neurology, psychiatry, cognitive neuroscience, electrical engineering, medical engineering, computer science&lt;/strong&gt;, and related fields.&lt;/p&gt;
&lt;p&gt;The successful applicant will be enrolled in the graduate psychology program by research. For non-local degree holders, GRE exams (general and subject) will be required for application. Find out more about the 
&lt;a href=&#34;http://psychology.hss.ntu.edu.sg/Programmes/Graduate/Pages/DoctorofPhilosophy.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graduate Program&lt;/a&gt; and its 
&lt;a href=&#34;http://admissions.ntu.edu.sg/graduate/R-Programs/Pages/default.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Online Application&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;Please address questions or send Curriculum Vita to 
&lt;a href=&#34;mailto:annabelchen@ntu.edu.sg&#34;&gt;annabelchen@ntu.edu.sg&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pyllusion</title>
      <link>https://clinicalbrainlab.github.io/software/pyllusion/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/pyllusion/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/software/pyllusion.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/RealityBending/Pyllusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pyllusion&lt;/a&gt; is a 
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; Toolbox that utilizes a parametric framework to generate visual illusions.&lt;/p&gt;
&lt;p&gt;The parametric approach implemented in this software proposes to describe illusions using a set of parameters, such as for instance the difference in the target features, and the strength of the contextual information in biasing the perception of the illusion (i.e., illusion strength). These two parameters can be modulated independently in &lt;em&gt;Pyllusion&lt;/em&gt; to investigate the precision and threshold at which certain populations become susceptible to the illusion. The aim of &lt;em&gt;Pyllusion&lt;/em&gt; is to foster reproducible science, allowing neuroscientists to easily report, generate and manipulate similar stimuli regardless of the display format and software. There is comprehensive 
&lt;a href=&#34;https://realitybending.github.io/Pyllusion/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; regarding the functionalities of &lt;em&gt;Pyllusion&lt;/em&gt; and code examples of how illusions can be generated in the form of images and psychopy stimuli.&lt;/p&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;p&gt;Pyllusion was presented at the &lt;strong&gt;43rd European Conference on Visual Perception (ECVP)&lt;/strong&gt;, held from 22 to 27 August 2021. A video walkthrough of the poster is available via this 
&lt;a href=&#34;https://www.youtube.com/watch?v=uptP_NxEHaM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube link&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Makowski, D., Lau, Z. J., Pham, T., Boyce, P., S H Chen, A. (in preparation). Pyllusion: A Parametric Framework to Generate Visual Illusions using Python.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/python/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/python/</guid>
      <description>&lt;h2 id=&#34;what-is-python&#34;&gt;What is Python?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; is general-purpose, free and open-source programming language for both software developers and researchers.
It is becoming increasingly 
&lt;a href=&#34;https://www.apa.org/science/about/psa/2019/07/python-research&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;popular amongst psychology researchers&lt;/a&gt;, allowing
researchers to create experiments, pre-process and clean data, as well as conduct statistical analyses and graphical visualization.&lt;/p&gt;
&lt;h2 id=&#34;building-experiments&#34;&gt;Building Experiments&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.psychopy.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PsychoPy&lt;/a&gt; is a Python package that has been used amongst psychology and neuroscientists to run cognitive experiments.
Not only does it comprise of a graphical user interface (GUI) so that novices can easily create simple experiments, more advanced customization can be included using Python code.&lt;/p&gt;
&lt;h2 id=&#34;data-wrangling&#34;&gt;Data Wrangling&lt;/h2&gt;
&lt;p&gt;Base Python consists of a series of modules that accommodates different functionalities. For example, the 
&lt;a href=&#34;https://pandas.pydata.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pandas&lt;/a&gt; module allows for importing, manipulation and organization of
text files, csv (comma-separated-values) files, or excel spreadsheets. The 
&lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scipy&lt;/a&gt; module is also made for statistical analyses, and 
&lt;a href=&#34;https://matplotlib.org/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matplotlib&lt;/a&gt;
for graphical visualization of data.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at Clinical Brain Lab use Python to analyze EEG and physiological (e.g., ECG, EDA, respiration, EMG, EOG) data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/r/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/r/</guid>
      <description>&lt;h2 id=&#34;what-is-r&#34;&gt;What is R?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.r-project.org/about.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R&lt;/a&gt; is a free programming language and software environment that comprises of a suite of pre-processing abilities (e.g., data manipulation
and cleaning), statistical analyses and modelling, and graphical visualization.&lt;/p&gt;
&lt;h2 id=&#34;most-ideal-for&#34;&gt;Most Ideal For&lt;/h2&gt;
&lt;p&gt;Behavioural Data&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at the Clinical Brain Lab use R extensively to pre-process behavioural data and conduct statistical analyses e.g., factor analysis, linear mixed effects models. We have also used it to host presentations!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SATA</title>
      <link>https://clinicalbrainlab.github.io/software/sata/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/software/sata/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/ClinicalBrainLab/SATA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SATA&lt;/a&gt; is a Matlab Based toolbox that works well with Matlab version 2017 and above.
However, we have not tested SATA for other MATLAB versions. SATA works on Windows, Linux and Mac. SATA is a post-processing toolbox after the tDCS montages have been simulated in COMETS or ROAST. To download the Graphical user interface (GUI) version of SATA, please visit 
&lt;a href=&#34;https://doi.org/10.21979/N9/DMWPZK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.21979/N9/DMWPZK&lt;/a&gt;. The SATA GUI package will allow the users to simulate the chosen montages in either COMETS or ROAST, and obtain the post-processed simulation outputs from SATA. Further, you may wish to not use the SATA GUI.
In this case, you can download the codes from the 
&lt;a href=&#34;https://github.com/ClinicalBrainLab/SATA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.
However, you will need to download SPM, Fieldtrip, and Talairach client (do add them to matlab path). Similarly, you will have to run COMETS or ROAST separately to generate simulation outputs.So please do download them from their respective websites and see how to use them from their manuals. For details on using the code of SATA, please refer the SATA MANUAL (section 3.4).&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Bhattacharjee, S., Kashyap, R., Rapp, B., Oishi, K., Desmond, J., &amp;amp; Chen, S. (2019). Simulation Analyses of tDCS Montages for the Investigation of Dorsal and Ventral Pathways. Scientific Reports (in press) doi: DOI: 10.1038/s41598-019-47654-y&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research Fellow Position in Science of Learning</title>
      <link>https://clinicalbrainlab.github.io/join/join_cbl_postdoc2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/join/join_cbl_postdoc2/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;background-color: #FFFF00&#34;&gt;&lt;strong&gt;Now Open for Applications&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are currently seeking highly motivated individuals who share our passion in deciphering the enigma of the brain to join us at the Clinical Brain Lab , Nanyang Technological University! We are seeking candidates interested in educational neuroscience.&lt;/p&gt;
&lt;h2 id=&#34;job-scope&#34;&gt;Job Scope&lt;/h2&gt;
&lt;p&gt;We are interested in building capacity for research in the &lt;em&gt;&lt;strong&gt;Science of Learning&lt;/strong&gt;&lt;/em&gt;, in particular in the area of educational neuroscience. We seek to understand how cognitive neuroscience can be applied to education to optimize learning. The successful candidate will work closely with researchers at the Centre for Research and Development in Learning (
&lt;a href=&#34;https://cradle.ntu.edu.sg/Pages/home.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRADLE&lt;/a&gt;), National Institute of Education (
&lt;a href=&#34;https://www.nie.edu.sg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NIE&lt;/a&gt;), and other international collaborators from institutes such as Johns Hopkins University, Massachusetts Institute of Technology and/or University of Cambridge. The &lt;strong&gt;current project will be investigating reading brain networks in bilingual children&lt;/strong&gt;. Singapore is a multicultural city that has a conducive education system to study this.&lt;/p&gt;
&lt;p&gt;The main research modalities in our lab include: neuropsychological assessments, cognitive tests, functional Magnetic Resonance (fMRI), diffusion MRI (DTI, HARDI, DSI), electroencephalography (EEG), Transcranial Magnetic Stimulation (TMS).&lt;/p&gt;
&lt;h2 id=&#34;looking-for&#34;&gt;Looking For&lt;/h2&gt;
&lt;p&gt;We welcome applicants with a &lt;strong&gt;doctorate (PhD)&lt;/strong&gt; degree in various backgrounds such as:
&lt;strong&gt;experimental psychology, biopsychology, cognitive psychology, neuropsychology, neurology,
psychiatry, cognitive neuroscience, electrical engineering, medical engineering, computer science&lt;/strong&gt;, and related fields.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;p&gt;Candidates are expected to have good interpersonal skills and to have demonstrated record of excellent scientific writing skills. Desirable qualification includes one or more of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experience with conducting behavioral experiments in neuropsychology or cognitive psychology.&lt;/li&gt;
&lt;li&gt;Experience with neuroimaging techniques (MRI/EEG/or TMS).&lt;/li&gt;
&lt;li&gt;Familiarity with image data analysis tools such as SPM, FSL, AFNI, DSIStudio, Matlab, Python etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;apply&#34;&gt;Apply&lt;/h2&gt;
&lt;p&gt;To apply, please use the 
&lt;a href=&#34;https://ntu.wd3.myworkdayjobs.com/Careers/job/NTU-Main-Campus-Singapore/Research-Fellow--Psychology-Cognitive-Neuroscience-Education-Science-of-Learning-_R00009385-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Workday platform&lt;/a&gt; or send Curriculum Vitae, letter of application with research interests, and three letters of recommendation to 
&lt;a href=&#34;mailto:annabelchen@ntu.edu.sg&#34;&gt;annabelchen@ntu.edu.sg&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contact information&lt;/strong&gt;: Professor S.H. Annabel Chen, PhD, Professor, of Psychology, School of Social Sciences, Nanyang Technological University, 48 Nanyang Drive, SHHK-04-19, Singapore 639818, phone +65-6316-8836&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SPM</title>
      <link>https://clinicalbrainlab.github.io/resources/tools/spm/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/tools/spm/</guid>
      <description>&lt;h2 id=&#34;what-is-spm&#34;&gt;What is SPM?&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.fil.ion.ucl.ac.uk/spm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPM&lt;/a&gt; or Statistical Parametric Mapping is a software package to analyze brain imaging sequences. It is designed to analyze data obtained from
fMRI, PET, SPECT, EEG and MEG.&lt;/p&gt;
&lt;h2 id=&#34;lab-use&#34;&gt;Lab Use&lt;/h2&gt;
&lt;p&gt;Researchers at the Clinical Brain Lab make use of SPM to analyze fMRI data when analyzing reading networks in bilingualism, as well as the neural correlates of deception.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial Direct Current Stimulation</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/tdcs/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/tdcs/</guid>
      <description>&lt;h2 id=&#34;what-is-tdcs&#34;&gt;What is tDCS?&lt;/h2&gt;
&lt;p&gt;tDCS (Transcranial Direct Current Stimulation) is a non-invasive and relatively painless brain stimulation technique that adjusts regional brain activity through modulating the transmembrane potential of neurons by sending low amplitude direct-current into the scalp.
In healthy populations, anodal tDCS has been shown to increase cortical excitability while cathodal tDCS has been shown to inhibit cortical excitability.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/tDCS.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-tdcs-done&#34;&gt;How is tDCS Done?&lt;/h2&gt;
&lt;p&gt;The electrode to be used is inserted into saline soaked sponges. The region where the electrode is to be placed is first wiped clean with alcohol wipes. Hair is then parted and the sponge is positioned over the marked position and secured in place using rubber straps.
When ready, the experimenter uses the DC-stimulator to start the stimulation.&lt;/p&gt;
&lt;h2 id=&#34;what-is-tdcs-used-for&#34;&gt;What is tDCS used for?&lt;/h2&gt;
&lt;p&gt;Currently in our lab, we are investigating effects of tDCS on cognitive tasks (e.g. reading) and exploring changes in brain activity as a result of tDCS using fNIRS.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial Magnetic Stimulation</title>
      <link>https://clinicalbrainlab.github.io/resources/techniques/tms/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://clinicalbrainlab.github.io/resources/techniques/tms/</guid>
      <description>&lt;h2 id=&#34;what-is-tms&#34;&gt;What is TMS?&lt;/h2&gt;
&lt;p&gt;TMS (Transcranial Magnetic Stimulation) is a non-invasive and painless tool that modulates neural activity. It works on the principle of Faraday’s law of electromagnetic induction.
In TMS, an electromagnetic coil sends a perpendicular magnetic field into the region of interest on the scalp. This field indirectly influences neuronal activity. TMS has been shown in some cases to induce cortical excitability and in some cases to depress excitability.
TMS can be administered in bursts at a rhythmic frequency (repetitive TMS) or as a single pulse. Repetitive TMS has been shown to have a greater and lasting effect. Depending on the question, rapid or slow repetitive TMS can be administered.&lt;/p&gt;
&lt;h2 id=&#34;how-is-tms-done&#34;&gt;How is TMS Done?&lt;/h2&gt;
&lt;p&gt;An electromyography (EMG) module is first attached via a wristband and by pasting electrodes onto the participant.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/TMS1.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;After setting up the parameters, an experimenter positions the magnetic coil above the participant’s scalp, over the region of interest. When activated, a high-current pulse is produced in the TMS coil, inducing a perpendicular magnetic field.
As high-current pulses are sent through the coil, the participant may hear clicks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://clinicalbrainlab.github.io/resources/techniques/TMS2.jpg&#34; alt=&#34;jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-tms-used-for&#34;&gt;What is TMS used for?&lt;/h2&gt;
&lt;p&gt;TMS can be used to treat clinical conditions (such as drug-resistant depression) or be used as an experimental technique to understand brain functions. In our lab, we are applying fMRI-guided TMS to target regions of the brain to determine its involvement in various cognitive networks.
We are also combining it with EEG to understand neuroplasticity.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://clinicalbrainlab.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cerebro-cerebellar pathways for verbal working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2019_cerebellum-working-memory-pathways/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2019_cerebellum-working-memory-pathways/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2018</title>
      <link>https://clinicalbrainlab.github.io/talk/2018_brainconnects/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2018_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2018/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2018.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working memory, age and education: A lifespan fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-education/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-education/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Functional connectivity of resting-state, working memory and inhibition networks in perceived stress</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_stress-working-memory/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_stress-working-memory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The role of regional heterogeneity in age-related differences in functional hemispheric asymmetry: an fMRI study</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-asymmetry/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-asymmetry/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2017</title>
      <link>https://clinicalbrainlab.github.io/talk/2017_brainconnects/</link>
      <pubDate>Tue, 22 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2017_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2017/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2017.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Frontal-subcortical circuitry in social attachment and relationships: A cross-sectional fMRI ALE meta-analysis</title>
      <link>https://clinicalbrainlab.github.io/publication/2017_meta-analysis-hot-cool/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2017_meta-analysis-hot-cool/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2016</title>
      <link>https://clinicalbrainlab.github.io/talk/2016_brainconnects/</link>
      <pubDate>Fri, 23 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2016_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2016/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2016.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reconciling individual differences with collective needs: The juxtaposition of sociopolitical and neuroscience perspectives on remediation and compensation of student skill deficits</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_learning-remediation-compensation/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_learning-remediation-compensation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modality specificity in the cerebro-cerebellar neurocircuitry during working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-modality/</link>
      <pubDate>Sun, 15 May 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-modality/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Higher Cognition &amp; the Cerebellum</title>
      <link>https://clinicalbrainlab.github.io/project/cerebellum/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/project/cerebellum/</guid>
      <description>&lt;p&gt;Cerebellum has increasingly been recognized for its contributions beyond motor control to higher cognitive functions. Our work focuses on the roles of cerebellum in working memory, i.e., the ability to hold information in short-term memory. We use neuroimaging techniques to examine the structural and functional connectivity of the cerebro-cerebellar pathways for verbal and visual working memory.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A comprehensive analysis of connectivity and aging over the adult life span</title>
      <link>https://clinicalbrainlab.github.io/publication/2018_ageing-connectivity/</link>
      <pubDate>Mon, 14 Mar 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2018_ageing-connectivity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Temporal dynamics of visual working memory</title>
      <link>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-dynamics/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/publication/2016_cerebellum-working-memory-dynamics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BrainConnects 2015</title>
      <link>https://clinicalbrainlab.github.io/talk/2015_brainconnects/</link>
      <pubDate>Fri, 31 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2015_brainconnects/</guid>
      <description>&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/site/brainconnects2nd/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2015.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BrainConnects 2014</title>
      <link>https://clinicalbrainlab.github.io/talk/2014_brainconnects/</link>
      <pubDate>Fri, 01 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://clinicalbrainlab.github.io/talk/2014_brainconnects/</guid>
      <description>







  
  


&lt;div class=&#34;gallery&#34;&gt;

  
  
  
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_group_1_2.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_group_1_2_hu9c1b6e0e5fd15c5d80344f1f32ec78bb_160480_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;261&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_nitish@.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_nitish@_huf92ead520f43847e8e6052e20a75e8e9_127385_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;311&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
  &lt;a data-fancybox=&#34;gallery-2014gallery&#34; href=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_workshopclosingremarks1.jpg&#34; &gt;
  &lt;img data-src=&#34;https://clinicalbrainlab.github.io/talk/2014_brainconnects/2014gallery/2014_workshopclosingremarks1_hub99cf81edab8a7224763508ad4c16a20_120048_0x190_resize_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;299&#34; height=&#34;190&#34;&gt;
  &lt;/a&gt;
  

  
&lt;/div&gt;
&lt;!-- TODO: fix broken link --&gt;
&lt;!-- Please click [here](https://clinicalbrain.org/events/brainconnects/Brain%20Connects%202014%20Workshop%20Program.pdf) for the workshop outline. --&gt;
&lt;p&gt;Follow 
&lt;a href=&#34;https://sites.google.com/view/brainconnects2014/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; link to the official website of BrainConnects 2014.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
